{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8b3a9f",
   "metadata": {},
   "source": [
    "# Scrape Data\n",
    "Jack Wilson\n",
    "9/23/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e71531",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8a9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fc566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968658e",
   "metadata": {},
   "source": [
    "# Scrape F1 Website [Race Results 2001-2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee0961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRAPING 2001 - 2017 URLS . . .\n",
      "SCRAPING 2001 - 2017 DATA . . .\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Establish web browser\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "# Establish year begin and end\n",
    "year_begin = 2001\n",
    "year_end = 2017\n",
    "\n",
    "# Establish empty lists\n",
    "race_urls = []\n",
    "\n",
    "print('SCRAPING 2001 - 2017 URLS . . .')\n",
    "while year_begin <= year_end:\n",
    "\n",
    "    # Use the year begin to be able to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "\n",
    "    # Find the table using the table tag\n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "    # Find the rows for each tr in the table\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "\n",
    "        # Find the data in each of the rows and append it to the proper list\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "    \n",
    "    year_begin += 1\n",
    "\n",
    "print('SCRAPING 2001 - 2017 DATA . . .')\n",
    "# Create a dictionary to map driver names to unique IDs\n",
    "driver_id_map = {}\n",
    "next_id = 1\n",
    "\n",
    "# Establish empty lists\n",
    "race_url = []\n",
    "position = []\n",
    "driver_name = []\n",
    "points = []\n",
    "driver_id = []\n",
    "\n",
    "# For each race link, open it and get data from the table\n",
    "for link in race_urls:\n",
    "    browser.get(link)\n",
    "\n",
    "    # Find the table using the table tag\n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "    # Find the rows for each tr in the table\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "\n",
    "        # Find the data in each of the rows and append it to the proper list\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            if len(cells) >= 6:\n",
    "                race_url.append(link)\n",
    "                position.append(cells[0].text)\n",
    "                driver_name.append(cells[2].text)\n",
    "                points.append(cells[6].text)\n",
    "                \n",
    "                # Assign unique driver ID\n",
    "                current_driver = cells[2].text\n",
    "                if current_driver not in driver_id_map:\n",
    "                    driver_id_map[current_driver] = next_id\n",
    "                    next_id += 1\n",
    "                driver_id.append(driver_id_map[current_driver])\n",
    "\n",
    "print('COMPLETE')\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7e78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the lists into a dataframe\n",
    "races_2001 = pd.DataFrame({\n",
    "    \"race_url\": race_url,\n",
    "    \"driver_id\": driver_id,\n",
    "    \"driver_name\": driver_name,\n",
    "    \"position\": position,\n",
    "    \"points\": points\n",
    "})\n",
    "\n",
    "# Save results\n",
    "races_2001.to_csv('../data/raw/races_results_raw_2001-2017.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221beaf9",
   "metadata": {},
   "source": [
    "# Scrape F1 Website [Race Results 2001-2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e92a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "races_2001 = pd.read_csv('../data/raw/races_results_raw_2001-2017.csv', encoding='utf-8')\n",
    "max_driver_id = races_2001['driver_id'].max()\n",
    "print(max_driver_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f81b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRAPING 2018 - 2025 URLS . . .\n",
      "SCRAPING 2018 - 2025 DATA . . .\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Establish web browser\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "# Establish year begin and end\n",
    "year_begin = 2018\n",
    "year_end = 2025\n",
    "\n",
    "# Establish empty lists\n",
    "race_urls = []\n",
    "\n",
    "print('SCRAPING 2018 - 2025 URLS . . .')\n",
    "while year_begin <= year_end:\n",
    "\n",
    "    # Use the year begin to be able to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "\n",
    "    # Find the table using the table tag\n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "    # Find the rows for each tr in the table\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "\n",
    "        # Find the data in each of the rows and append it to the proper list\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "    \n",
    "    year_begin += 1\n",
    "\n",
    "print('SCRAPING 2018 - 2025 DATA . . .')\n",
    "# Create a dictionary to map driver, race, and circuit names to unique IDs\n",
    "driver_id_map = {}\n",
    "race_id_map = {}\n",
    "circuit_id_map = {}\n",
    "\n",
    "next_driver_id = max_driver_id + 1\n",
    "next_race_id = 1\n",
    "next_circuit_id = 1\n",
    "\n",
    "# Establish empty lists\n",
    "driver_id = []\n",
    "race_id = []\n",
    "circuit_id = []\n",
    "year = []\n",
    "rounds = []\n",
    "driver_name = []\n",
    "team_name = []\n",
    "circuit_names = []\n",
    "end_position = []\n",
    "points = []\n",
    "laps_completed = []\n",
    "\n",
    "\n",
    "# For each race link, open it and get data from the table\n",
    "current_year = None\n",
    "repr = 0\n",
    "\n",
    "for link in race_urls:\n",
    "    browser.get(link)\n",
    "    \n",
    "    # Extract year from URL\n",
    "    race_year = link.split('/')[5]\n",
    "    \n",
    "    # Extract circuit name from URL\n",
    "    circuit_name = link.split('/')[7]\n",
    "    \n",
    "    # Reset round counter when year changes\n",
    "    if race_year != current_year:\n",
    "        current_year = race_year\n",
    "        r = 1\n",
    "    else:\n",
    "        r += 1\n",
    "\n",
    "    # Assign unique race ID (combination of year and round)\n",
    "    race_key = f\"{race_year}_{r}\"\n",
    "    if race_key not in race_id_map:\n",
    "        race_id_map[race_key] = next_race_id\n",
    "        next_race_id += 1\n",
    "    \n",
    "    # Assign unique circuit ID (circuit name should repeat in subsequent years)\n",
    "    if circuit_name not in circuit_id_map:\n",
    "        circuit_id_map[circuit_name] = next_circuit_id\n",
    "        next_circuit_id += 1\n",
    "\n",
    "    # Find the table using the table tag\n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "    # Find the rows for each tr in the table\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "\n",
    "        # Find the data in each of the rows and append it to the proper list\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            if len(cells) >= 6:\n",
    "                end_position.append(cells[0].text)\n",
    "                driver_name.append(cells[2].text)\n",
    "                team_name.append(cells[3].text)\n",
    "                laps_completed.append(cells[4].text)\n",
    "                points.append(cells[6].text)\n",
    "                circuit_names.append(circuit_name)\n",
    "                year.append(race_year)\n",
    "                rounds.append(r)\n",
    "                \n",
    "                # Assign unique driver, race, and circuit IDs\n",
    "                current_driver = cells[2].text\n",
    "                if current_driver not in driver_id_map:\n",
    "                    driver_id_map[current_driver] = next_driver_id\n",
    "                    next_driver_id += 1\n",
    "                driver_id.append(driver_id_map[current_driver])\n",
    "                race_id.append(race_id_map[race_key])\n",
    "                circuit_id.append(circuit_id_map[circuit_name])\n",
    "\n",
    "print('COMPLETE')\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d6ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the lists into a dataframe\n",
    "races_2018 = pd.DataFrame({\n",
    "    'driver_id': driver_id,\n",
    "    'race_id': race_id,\n",
    "    'circuit_id': circuit_id,\n",
    "    'year': year,\n",
    "    'round_number': rounds,\n",
    "    'circuit_name': circuit_names,\n",
    "    'driver_name': driver_name,\n",
    "    'team_name': team_name,\n",
    "    'end_position': end_position,\n",
    "    'points': points,\n",
    "    'laps_completed': laps_completed\n",
    "})\n",
    "\n",
    "# Save results\n",
    "races_2018.to_csv('../data/raw/races_results_raw_2018-2025.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00569f46",
   "metadata": {},
   "source": [
    "# Weather Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c523242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Australian Grand Prix - Practice 1 [v3.6.1]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for weather_data. Loading data...\n",
      "_api           INFO \tFetching weather data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['2', '3', '5', '7', '8', '9', '10', '11', '14', '16', '18', '20', '27', '28', '31', '33', '35', '44', '55', '77']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Time  AirTemp  Humidity  Pressure  Rainfall  TrackTemp  \\\n",
      "0 0 days 00:00:24.964000     25.3      36.7    1020.2     False       38.5   \n",
      "1 0 days 00:01:24.977000     25.4      36.9    1020.0     False       38.5   \n",
      "2 0 days 00:02:24.990000     25.2      36.8    1020.1     False       38.5   \n",
      "3 0 days 00:03:25.002000     25.3      36.1    1020.1     False       38.5   \n",
      "4 0 days 00:04:25.014000     25.4      35.9    1020.0     False       38.6   \n",
      "\n",
      "   WindDirection  WindSpeed  \n",
      "0            330        2.6  \n",
      "1            308        2.5  \n",
      "2            305        2.7  \n",
      "3            305        2.5  \n",
      "4            325        2.8  \n"
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "\n",
    "# Enable cache (important for performance)\n",
    "#fastf1.Cache.enable_cache(\"cache\")  # creates a folder \"cache\" to store data\n",
    "\n",
    "# Load a session: example Bahrain GP 2023 Qualifying\n",
    "session = fastf1.get_session(2018, 'australia', 'fp1')\n",
    "session.load(laps=False, telemetry=False, messages=False)  # downloads and parses the data\n",
    "\n",
    "# Weather data is stored in session.weather_data (a structured numpy array)\n",
    "weather_array = session.weather_data\n",
    "\n",
    "# Convert to DataFrame\n",
    "weather_df = pd.DataFrame(weather_array)\n",
    "\n",
    "print(weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ec627bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AirTemp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>TrackTemp</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 00:00:41.425000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>False</td>\n",
       "      <td>29.8</td>\n",
       "      <td>338</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 00:01:41.221000</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>False</td>\n",
       "      <td>29.7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 00:02:41.235000</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>False</td>\n",
       "      <td>29.6</td>\n",
       "      <td>323</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 00:03:41.250000</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>False</td>\n",
       "      <td>29.6</td>\n",
       "      <td>345</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 00:04:41.264000</td>\n",
       "      <td>24.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>False</td>\n",
       "      <td>29.5</td>\n",
       "      <td>355</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0 days 01:30:41.640000</td>\n",
       "      <td>23.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>False</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0 days 01:31:41.639000</td>\n",
       "      <td>23.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>False</td>\n",
       "      <td>26.7</td>\n",
       "      <td>311</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0 days 01:32:41.638000</td>\n",
       "      <td>23.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>False</td>\n",
       "      <td>26.7</td>\n",
       "      <td>318</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0 days 01:33:41.637000</td>\n",
       "      <td>23.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>False</td>\n",
       "      <td>26.7</td>\n",
       "      <td>332</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0 days 01:34:41.635000</td>\n",
       "      <td>23.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1017.7</td>\n",
       "      <td>False</td>\n",
       "      <td>26.7</td>\n",
       "      <td>335</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time  AirTemp  Humidity  Pressure  Rainfall  TrackTemp  \\\n",
       "0  0 days 00:00:41.425000     24.7      17.0    1017.5     False       29.8   \n",
       "1  0 days 00:01:41.221000     24.6      17.0    1017.5     False       29.7   \n",
       "2  0 days 00:02:41.235000     24.6      17.0    1017.5     False       29.6   \n",
       "3  0 days 00:03:41.250000     24.6      17.0    1017.5     False       29.6   \n",
       "4  0 days 00:04:41.264000     24.6      18.0    1017.4     False       29.5   \n",
       "..                    ...      ...       ...       ...       ...        ...   \n",
       "90 0 days 01:30:41.640000     23.1      33.0    1017.9     False       26.7   \n",
       "91 0 days 01:31:41.639000     23.1      33.0    1017.9     False       26.7   \n",
       "92 0 days 01:32:41.638000     23.1      33.0    1017.9     False       26.7   \n",
       "93 0 days 01:33:41.637000     23.1      33.0    1017.9     False       26.7   \n",
       "94 0 days 01:34:41.635000     23.1      34.0    1017.7     False       26.7   \n",
       "\n",
       "    WindDirection  WindSpeed  \n",
       "0             338        0.8  \n",
       "1              17        0.8  \n",
       "2             323        0.5  \n",
       "3             345        1.0  \n",
       "4             355        0.8  \n",
       "..            ...        ...  \n",
       "90              0        1.1  \n",
       "91            311        0.4  \n",
       "92            318        1.2  \n",
       "93            332        1.0  \n",
       "94            335        1.2  \n",
       "\n",
       "[95 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirTemp_mean        23.880000\n",
      "AirTemp_min         23.000000\n",
      "AirTemp_max         24.700000\n",
      "AirTemp_std          0.527660\n",
      "TrackTemp_mean      28.085263\n",
      "TrackTemp_min       26.600000\n",
      "TrackTemp_max       29.800000\n",
      "TrackTemp_std        0.970629\n",
      "WindSpeed_mean       0.607368\n",
      "WindSpeed_min        0.000000\n",
      "WindSpeed_max        1.300000\n",
      "WindSpeed_std        0.356174\n",
      "Humidity_mean       21.652632\n",
      "Humidity_min        15.000000\n",
      "Humidity_max        34.000000\n",
      "Humidity_std         6.799200\n",
      "Pressure_mean     1017.641053\n",
      "Pressure_min      1017.400000\n",
      "Pressure_max      1017.900000\n",
      "Pressure_std         0.132484\n",
      "RainAffected         0.000000\n",
      "RainFraction         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def aggregate_weather(weather_df):\n",
    "    agg = {}\n",
    "    for col in ['AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity', 'Pressure']:\n",
    "        agg[f'{col}_mean'] = weather_df[col].mean()\n",
    "        agg[f'{col}_min'] = weather_df[col].min()\n",
    "        agg[f'{col}_max'] = weather_df[col].max()\n",
    "        agg[f'{col}_std'] = weather_df[col].std()\n",
    "    \n",
    "    # Rain flag and proportion\n",
    "    agg['RainAffected'] = int(weather_df['Rainfall'].any())\n",
    "    agg['RainFraction'] = weather_df['Rainfall'].mean()\n",
    "    \n",
    "    return pd.Series(agg)\n",
    "\n",
    "# Usage\n",
    "session_weather_features = aggregate_weather(weather_df)\n",
    "print(session_weather_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995c9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
