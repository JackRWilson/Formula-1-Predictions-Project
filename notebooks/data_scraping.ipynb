{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8b3a9f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Jack Wilson\n",
    "9/23/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7868b9",
   "metadata": {},
   "source": [
    "This notebook outlines scraping and collecting of all data raw data used in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e71531",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8a9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, random, re, os, gc, shutil, pickle, tempfile, os, sys\n",
    "from math import e\n",
    "\n",
    "import fastf1\n",
    "import logging\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f87135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path Setup: Connects Notebook to 'src' Package\n",
    "\n",
    "# Add the project root (one level up from 'notebooks/') to the system path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.data_functions import load_id_map, save_id_map, init_col_map, scrape_url_table, constructor_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7736f",
   "metadata": {},
   "source": [
    "# DataFrame Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fc566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968658e",
   "metadata": {},
   "source": [
    "# F1 Site 2001-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6714b5",
   "metadata": {},
   "source": [
    "## Race Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ee0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish web browser and initial variables\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "year_begin = 2001\n",
    "year_end = 2017\n",
    "race_urls = []\n",
    "\n",
    "while year_begin <= year_end:\n",
    "\n",
    "    # Use the years to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "    \n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "    \n",
    "    year_begin += 1\n",
    "\n",
    "browser.close()\n",
    "\n",
    "# Save links to file\n",
    "load_id_map('../data/raw/links_2001_2017.pkl')\n",
    "save_id_map('../data/raw/links_2001_2017.pkl', race_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83756d04",
   "metadata": {},
   "source": [
    "## Race Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581437d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables\n",
    "urls = load_id_map('../data/raw/links_2001_2017.pkl')\n",
    "total_cols = 7\n",
    "col_idx_map = {\n",
    "    'driver_id': 2,\n",
    "    'position': 0,\n",
    "    'driver_name': 2,\n",
    "    'points': 6}\n",
    "id_cols = ['driver_id']\n",
    "\n",
    "# Scrape 2001-2017 results\n",
    "df = scrape_url_table(\n",
    "    urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols)\n",
    "df.to_csv('../data/raw/race_results_raw_2001-2017.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164dcb2",
   "metadata": {},
   "source": [
    "# F1 Site 2018+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23231d0",
   "metadata": {},
   "source": [
    "## Race Links & Circuit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2be5511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish web browser and initial variables\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "year_begin = 2018\n",
    "year_end = datetime.now().year\n",
    "race_urls = []\n",
    "round_number = []\n",
    "\n",
    "while year_begin <= year_end:\n",
    "    r = 1  \n",
    "\n",
    "    # Use the years to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "    \n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "            round_number.append(r)\n",
    "            r += 1 \n",
    "\n",
    "    year_begin += 1\n",
    "\n",
    "browser.close()\n",
    "\n",
    "link_data = pd.DataFrame({'race_url': race_urls, 'round_number': round_number})\n",
    "link_data.to_csv('../data/raw/rounds_raw.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# Save links to file\n",
    "load_id_map('../data/raw/links_2018+.pkl')\n",
    "save_id_map('../data/raw/links_2018+.pkl', race_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9903d16",
   "metadata": {},
   "source": [
    "## Race Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "total_cols = 7\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'circuit_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text,\n",
    "    'team_id': 3,\n",
    "    'year': lambda browser: int(browser.current_url.split(\"/\")[5]),\n",
    "    'race_url': lambda browser: browser.current_url,\n",
    "    'circuit_name': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text,\n",
    "    'driver_name': 2,\n",
    "    'team_name': 3,\n",
    "    'end_position': 0,\n",
    "    'points': 6,\n",
    "    'laps_completed': 4}\n",
    "id_cols = ['race_id', 'driver_id', 'circuit_id', 'team_id']\n",
    "page_lvl_cols = ['race_id', 'circuit_id', 'year', 'race_url', 'circuit_name']\n",
    "\n",
    "# Scrape 2018+ results\n",
    "df = scrape_url_table(\n",
    "    urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/race_results_raw_2018+.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754febc2",
   "metadata": {},
   "source": [
    "## Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create practice URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "practice_urls = []\n",
    "for url in urls:\n",
    "    for practice_num in [1, 2, 3]:\n",
    "        practice_url = url.replace('/race-result', f'/practice/{practice_num}')\n",
    "        practice_urls.append(practice_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 6\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'session_type': lambda browser: browser.current_url.split(\"/\")[9] + browser.current_url.split(\"/\")[10],\n",
    "    'lap_time': 4,\n",
    "    'lap_count': 5,\n",
    "    'position': 0}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id', 'session_type']\n",
    "\n",
    "# Scrape practice results\n",
    "df = scrape_url_table(\n",
    "    practice_urls,\n",
    "    total_cols, col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/pratice_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bef32a",
   "metadata": {},
   "source": [
    "## Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create qualifying URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "qualifying_urls = []\n",
    "for url in urls:\n",
    "    qual_url = url.replace('/race-result', '/qualifying')\n",
    "    qualifying_urls.append(qual_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'q1_time': 4,\n",
    "    'q2_time': 5,\n",
    "    'q3_time': 6,\n",
    "    'qual_position': 0,\n",
    "    'qual_laps': 7}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape qualifying results\n",
    "df = scrape_url_table(\n",
    "    qualifying_urls,\n",
    "    total_cols, col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/qualifying_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c87aa8",
   "metadata": {},
   "source": [
    "## Starting Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e59620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create starting grid URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "starting_urls = []\n",
    "for url in urls:\n",
    "    start_url = url.replace('/race-result', '/starting-grid')\n",
    "    starting_urls.append(start_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 5\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'start_position': 0}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape starting grid results\n",
    "df = scrape_url_table(\n",
    "    starting_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/starting_grid_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ec1b3",
   "metadata": {},
   "source": [
    "## Pit Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b56251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pit stop URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "pit_urls = []\n",
    "for url in urls:\n",
    "    ps_url = url.replace('/race-result', '/pit-stop-summary')\n",
    "    pit_urls.append(ps_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'stop_number': 0,\n",
    "    'stop_lap': 4,\n",
    "    'pits_time': 6}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape pit stop results\n",
    "df = scrape_url_table(\n",
    "    pit_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/pit_stop_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d51364",
   "metadata": {},
   "source": [
    "## Fastest Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission denied on attempt 1, retrying in 1 second...\n"
     ]
    }
   ],
   "source": [
    "# Create fastest lap URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "fastest_lap_urls = []\n",
    "for url in urls:\n",
    "    fastest_url = url.replace('/race-result', '/fastest-laps')\n",
    "    fastest_lap_urls.append(fastest_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'fastest_lap_time': 6,\n",
    "    'lap_number': 4}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape fastest lap results\n",
    "df = scrape_url_table(\n",
    "    fastest_lap_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/fastest_lap_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924b539",
   "metadata": {},
   "source": [
    "# FastF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ddf47",
   "metadata": {},
   "source": [
    "## Create Driver Code Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lewis Hamilton: HAM\n",
      "✓ Valtteri Bottas: BOT\n",
      "✓ Max Verstappen: VER\n",
      "✓ Kimi Räikkönen: RAI\n",
      "✓ Sebastian Vettel: VET\n",
      "✓ Daniel Ricciardo: RIC\n",
      "✓ Romain Grosjean: GRO\n",
      "✓ Fernando Alonso: ALO\n",
      "✓ Carlos Sainz: SAI\n",
      "✓ Stoffel Vandoorne: VAN\n",
      "✓ Pierre Gasly: GAS\n",
      "✓ Sergey Sirotkin: SIR\n",
      "✓ Nico Hulkenberg: HUL\n",
      "✓ Esteban Ocon: OCO\n",
      "✓ Lance Stroll: STR\n",
      "✓ Sergio Perez: PER\n",
      "✓ Kevin Magnussen: MAG\n",
      "✓ Brendon Hartley: HAR\n",
      "✓ Marcus Ericsson: ERI\n",
      "✓ Charles Leclerc: LEC\n",
      "✓ Robert Kubica: KUB\n",
      "✓ Nicholas Latifi: LAT\n",
      "✓ Antonio Giovinazzi: GIO\n",
      "✓ Lando Norris: NOR\n",
      "✓ Artem Markelov: MAR\n",
      "✓ Sean Gelael: GEL\n",
      "✓ Daniil Kvyat: KVY\n",
      "✓ Alexander Albon: ALB\n",
      "✓ George Russell: RUS\n",
      "✓ Naoki Yamamoto: YAM\n",
      "✓ Jack Aitken: AIT\n",
      "✓ Roy Nissany: NIS\n",
      "✓ Pietro Fittipaldi: FIT\n",
      "✓ Mick Schumacher: MSC\n",
      "✓ Yuki Tsunoda: TSU\n",
      "✓ Nikita Mazepin: MAZ\n",
      "✓ Callum Ilott: ILO\n",
      "✓ Zhou Guanyu: ZHO\n",
      "✓ Nyck De Vries: DEV\n",
      "✓ Juri Vips: VIP\n",
      "✓ Liam Lawson: LAW\n",
      "✓ Robert Shwartzman: SHW\n",
      "✓ Alex Palou: PAL\n",
      "✓ Theo Pourchaire: POU\n",
      "✓ Logan Sargeant: SAR\n",
      "✓ Jack Doohan: DOO\n",
      "✓ Patricio O'Ward: OWA\n",
      "✓ Felipe Drugovich: DRU\n",
      "✓ Oscar Piastri: PIA\n",
      "✓ Oliver Bearman: BEA\n",
      "✓ Isack Hadjar: HAD\n",
      "✓ Frederik Vesti: VES\n",
      "✓ Jake Dennis: DEN\n",
      "✓ Zak O'Sullivan: OSU\n",
      "✓ Ayumu Iwasa: IWA\n",
      "✓ Franco Colapinto: COL\n",
      "✓ Kimi Antonelli: ANT\n",
      "✓ Ryo Hirakawa: HIR\n",
      "✓ Arthur Leclerc: LEL\n",
      "✓ Luke Browning: BRO\n",
      "✓ Gabriel Bortoleto: BOR\n",
      "✓ Dino Beganovic: BEG\n",
      "✓ Victor Martins: MAR\n",
      "✓ Alexander Dunne: DUN\n",
      "✓ Arvid Lindblad: LIN\n",
      "✓ Paul Aron: ARO\n",
      "\n",
      "==================================================\n",
      "Total drivers found: 66\n",
      "Failed URLs: 0\n"
     ]
    }
   ],
   "source": [
    "# Establish web browser and initial variables\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "practice_urls = []\n",
    "for url in urls:\n",
    "    for practice_num in [1, 2, 3]:\n",
    "        practice_url = url.replace('/race-result', f'/practice/{practice_num}')\n",
    "        practice_urls.append(practice_url)\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "driver_code_map = {}\n",
    "failed_urls = []\n",
    "\n",
    "# Parse urls\n",
    "for url in practice_urls:\n",
    "    try:\n",
    "        browser.get(url)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        tables = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "        if not tables:\n",
    "            print(f\"No tables found on {url}\")\n",
    "            continue\n",
    "            \n",
    "        for table in tables:\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "            \n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    \n",
    "                    if len(cells) < 3:\n",
    "                        continue\n",
    "\n",
    "                    driver_cell = cells[2]\n",
    "                    \n",
    "                    # Get all text content from the cell\n",
    "                    cell_html = driver_cell.get_attribute('innerHTML')\n",
    "                    \n",
    "                    # Extract name and code\n",
    "                    try:\n",
    "                        # Get all span text\n",
    "                        all_spans = driver_cell.find_elements(By.TAG_NAME, 'span')\n",
    "                        \n",
    "                        # Collect name parts\n",
    "                        name_parts = []\n",
    "                        driver_code = ''\n",
    "                        \n",
    "                        for span in all_spans:\n",
    "                            classes = span.get_attribute('class') or ''\n",
    "                            text = span.get_attribute('textContent').strip()\n",
    "                            \n",
    "                            if not text:\n",
    "                                continue\n",
    "                            \n",
    "                            # Name spans\n",
    "                            if 'max-lg:hidden' in classes or 'max-md:hidden' in classes:\n",
    "                                name_parts.append(text)\n",
    "                            # Code span\n",
    "                            elif 'md:hidden' in classes and not driver_code:\n",
    "                                driver_code = text\n",
    "                        \n",
    "                        full_name = \" \".join(name_parts)\n",
    "                        \n",
    "                        # Save if we have both name and code and haven't seen this name\n",
    "                        if full_name and driver_code and full_name not in driver_code_map:\n",
    "                            driver_code_map[full_name] = driver_code\n",
    "                            print(f\"{full_name}: {driver_code}\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        # Skip rows with parsing issues\n",
    "                        continue\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    # Skip problematic rows\n",
    "                    continue\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {url}: {e}\")\n",
    "        failed_urls.append(url)\n",
    "        continue\n",
    "\n",
    "browser.close()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total drivers found: {len(driver_code_map)}\")\n",
    "print(f\"Failed URLs: {len(failed_urls)}\")\n",
    "if failed_urls:\n",
    "    print(\"Failed URLs:\")\n",
    "    for url in failed_urls[:5]:\n",
    "        print(f\"  - {url}\")\n",
    "\n",
    "# Save driver code map to file\n",
    "save_id_map('../data/raw/driver_code_map.pkl', driver_code_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4de9cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names in driver_code_map but not in driver_id_map (0):\n",
      "\n",
      "Names in driver_id_map but not in driver_code_map (90):\n",
      "  Adrian Sutil -> 59\n",
      "  Alex Yoong -> 26\n",
      "  Alexander Dunne -> 148\n",
      "  Alexander Rossi -> 96\n",
      "  Alexander Wurz -> 48\n",
      "  Allan McNish -> 31\n",
      "  Andre Lotterer -> 90\n",
      "  Anthony Davidson -> 32\n",
      "  Antonio Pizzonia -> 33\n",
      "  Arvid Lindblad -> 149\n",
      "  Bruno Senna -> 71\n",
      "  Charles Pic -> 81\n",
      "  Christian Klien -> 40\n",
      "  Christijan Albers -> 47\n",
      "  Cristiano da Matta -> 35\n",
      "  David Coulthard -> 2\n",
      "  Dino Beganovic -> 146\n",
      "  Eddie Irvine -> 11\n",
      "  Enrique Bernoldi -> 21\n",
      "  Esteban Gutierrez -> 82\n",
      "  Felipe Massa -> 30\n",
      "  Felipe Nasr -> 92\n",
      "  Franck Montagny -> 54\n",
      "  Gabriel Bortoleto -> 126\n",
      "  Gaston Mazzacane -> 22\n",
      "  Giancarlo Fisichella -> 13\n",
      "  Gianmaria Bruni -> 42\n",
      "  Giedo van der Garde -> 86\n",
      "  Giorgio Pantano -> 41\n",
      "  Heikki Kovalainen -> 58\n",
      "  Heinz-Harald Frentzen -> 5\n",
      "  Jacques Villeneuve -> 19\n",
      "  Jaime Alguersuari -> 66\n",
      "  Jarno Trulli -> 16\n",
      "  Jean Alesi -> 9\n",
      "  Jean-Eric Vergne -> 80\n",
      "  Jenson Button -> 14\n",
      "  Jerome d'Ambrosio -> 77\n",
      "  Jolyon Palmer -> 97\n",
      "  Jos Verstappen -> 10\n",
      "  Juan Pablo Montoya -> 15\n",
      "  Jules Bianchi -> 84\n",
      "  Justin Wilson -> 34\n",
      "  Kamui Kobayashi -> 69\n",
      "  Karun Chandhok -> 74\n",
      "  Kazuki Nakajima -> 62\n",
      "  Luca Badoer -> 68\n",
      "  Lucas di Grassi -> 73\n",
      "  Luciano Burti -> 8\n",
      "  Marc Gene -> 39\n",
      "  Mark Webber -> 27\n",
      "  Markus Winkelhock -> 61\n",
      "  Max Chilton -> 85\n",
      "  Michael Schumacher -> 1\n",
      "  Mika Hakkinen -> 17\n",
      "  Mika Salo -> 28\n",
      "  Narain Karthikeyan -> 44\n",
      "  Nelson Piquet -> 64\n",
      "  Nick Heidfeld -> 4\n",
      "  Nico Rosberg -> 51\n",
      "  Nicolas Kiesa -> 37\n",
      "  Olivier Panis -> 7\n",
      "  Pascal Wehrlein -> 98\n",
      "  Pastor Maldonado -> 78\n",
      "  Patrick Friesacher -> 46\n",
      "  Paul Aron -> 150\n",
      "  Paul di Resta -> 76\n",
      "  Pedro de la Rosa -> 23\n",
      "  Ralf Schumacher -> 18\n",
      "  Ralph Firman -> 36\n",
      "  Ricardo Zonta -> 24\n",
      "  Rio Haryanto -> 99\n",
      "  Robert Doornbos -> 50\n",
      "  Roberto Merhi -> 95\n",
      "  Rubens Barrichello -> 3\n",
      "  Sakon Yamamoto -> 55\n",
      "  Scott Speed -> 52\n",
      "  Sebastien Bourdais -> 63\n",
      "  Sebastien Buemi -> 65\n",
      "  Takuma Sato -> 29\n",
      "  Tarso Marques -> 20\n",
      "  Tiago Monteiro -> 45\n",
      "  Timo Glock -> 43\n",
      "  Tomas Enge -> 25\n",
      "  Victor Martins -> 147\n",
      "  Vitaly Petrov -> 72\n",
      "  Vitantonio Liuzzi -> 49\n",
      "  Will Stevens -> 91\n",
      "  Yuji Ide -> 53\n",
      "  Zsolt Baumgartner -> 38\n",
      "\n",
      "Total driver_code_map entries: 60\n",
      "Total driver_id_map entries: 150\n"
     ]
    }
   ],
   "source": [
    "driver_code_map = load_id_map('../data/raw/driver_code_map.pkl')\n",
    "driver_id_map = pd.read_pickle('../data/raw/driver_id_map.pkl')\n",
    "\n",
    "# Compare driver names between the two maps\n",
    "code_names = set(driver_code_map.keys())\n",
    "id_names = set(driver_id_map.keys())\n",
    "\n",
    "# Find names in driver_code_map but not in driver_id_map\n",
    "missing_in_id = code_names - id_names\n",
    "print(f\"Names in driver_code_map but not in driver_id_map ({len(missing_in_id)}):\")\n",
    "for name in sorted(missing_in_id):\n",
    "    print(f\"  {name} -> {driver_code_map[name]}\")\n",
    "\n",
    "# Find names in driver_id_map but not in driver_code_map\n",
    "missing_in_code = id_names - code_names\n",
    "print(f\"\\nNames in driver_id_map but not in driver_code_map ({len(missing_in_code)}):\")\n",
    "for name in sorted(missing_in_code):\n",
    "    print(f\"  {name} -> {driver_id_map[name]}\")\n",
    "\n",
    "print(f\"\\nTotal driver_code_map entries: {len(driver_code_map)}\")\n",
    "print(f\"Total driver_id_map entries: {len(driver_id_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8eef68",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b558156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1180 rows after filtering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_name</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>circuit_id</th>\n",
       "      <th>session</th>\n",
       "      <th>avg_pace_soft</th>\n",
       "      <th>std_pace_soft</th>\n",
       "      <th>laps_on_soft</th>\n",
       "      <th>deg_rate_soft</th>\n",
       "      <th>avg_pace_medium</th>\n",
       "      <th>std_pace_medium</th>\n",
       "      <th>laps_on_medium</th>\n",
       "      <th>deg_rate_medium</th>\n",
       "      <th>avg_pace_hard</th>\n",
       "      <th>std_pace_hard</th>\n",
       "      <th>laps_on_hard</th>\n",
       "      <th>deg_rate_hard</th>\n",
       "      <th>avg_pace_intermediate</th>\n",
       "      <th>std_pace_intermediate</th>\n",
       "      <th>laps_on_intermediate</th>\n",
       "      <th>deg_rate_intermediate</th>\n",
       "      <th>avg_pace_wet</th>\n",
       "      <th>std_pace_wet</th>\n",
       "      <th>laps_on_wet</th>\n",
       "      <th>deg_rate_wet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.376167</td>\n",
       "      <td>4.715031</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.469674</td>\n",
       "      <td>99.533585</td>\n",
       "      <td>3.187425</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.135769</td>\n",
       "      <td>2.682735</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.088043</td>\n",
       "      <td>97.925529</td>\n",
       "      <td>4.407023</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.194301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.304652</td>\n",
       "      <td>2.216822</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.183065</td>\n",
       "      <td>97.172278</td>\n",
       "      <td>3.012149</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.047907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.463955</td>\n",
       "      <td>2.736229</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.144508</td>\n",
       "      <td>98.132789</td>\n",
       "      <td>2.906845</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.103551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.087083</td>\n",
       "      <td>4.192109</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.431698</td>\n",
       "      <td>99.118170</td>\n",
       "      <td>3.808767</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.018198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>100.676769</td>\n",
       "      <td>3.755982</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.341254</td>\n",
       "      <td>99.005711</td>\n",
       "      <td>2.517406</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.022230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.153200</td>\n",
       "      <td>5.213129</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.462618</td>\n",
       "      <td>100.213130</td>\n",
       "      <td>3.667841</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.207696</td>\n",
       "      <td>99.402731</td>\n",
       "      <td>3.824296</td>\n",
       "      <td>26</td>\n",
       "      <td>0.058163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.721105</td>\n",
       "      <td>2.752830</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.137761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.729200</td>\n",
       "      <td>2.958193</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>96.814357</td>\n",
       "      <td>4.200845</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.093629</td>\n",
       "      <td>98.779043</td>\n",
       "      <td>2.508297</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.105267</td>\n",
       "      <td>97.170800</td>\n",
       "      <td>4.017064</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.275383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.061882</td>\n",
       "      <td>6.046062</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.318838</td>\n",
       "      <td>99.598708</td>\n",
       "      <td>2.762410</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.118865</td>\n",
       "      <td>100.818368</td>\n",
       "      <td>6.393824</td>\n",
       "      <td>19</td>\n",
       "      <td>0.163630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.619308</td>\n",
       "      <td>5.122376</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.841077</td>\n",
       "      <td>99.329043</td>\n",
       "      <td>2.298623</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.018784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.476526</td>\n",
       "      <td>2.299503</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.214341</td>\n",
       "      <td>97.487550</td>\n",
       "      <td>2.885487</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.004969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.744958</td>\n",
       "      <td>1.759141</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.140507</td>\n",
       "      <td>96.720000</td>\n",
       "      <td>2.664941</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.619069</td>\n",
       "      <td>3.211223</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.124563</td>\n",
       "      <td>99.447900</td>\n",
       "      <td>3.214728</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.066887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.885080</td>\n",
       "      <td>2.011911</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.160078</td>\n",
       "      <td>96.653059</td>\n",
       "      <td>3.421423</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.076244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.405478</td>\n",
       "      <td>1.489478</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.095824</td>\n",
       "      <td>96.797056</td>\n",
       "      <td>2.798527</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.055593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>97.149545</td>\n",
       "      <td>5.120128</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.843082</td>\n",
       "      <td>99.306604</td>\n",
       "      <td>2.684240</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.043094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.490108</td>\n",
       "      <td>2.677640</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.050600</td>\n",
       "      <td>98.429318</td>\n",
       "      <td>3.709107</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.295469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TSU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>101.316667</td>\n",
       "      <td>4.535980</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.457225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.501106</td>\n",
       "      <td>2.907594</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.040241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.001000</td>\n",
       "      <td>1.833117</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.200035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.750929</td>\n",
       "      <td>2.599772</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.041971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_name  driver_id race_id  circuit_id session  avg_pace_soft  \\\n",
       "0          ALB        NaN     167         NaN    Race      98.376167   \n",
       "1          ALO        NaN     167         NaN    Race      99.135769   \n",
       "2          ANT        NaN     167         NaN    Race            NaN   \n",
       "3          BEA        NaN     167         NaN    Race            NaN   \n",
       "4          BOR        NaN     167         NaN    Race            NaN   \n",
       "5          COL        NaN     167         NaN    Race     100.676769   \n",
       "6          GAS        NaN     167         NaN    Race      98.153200   \n",
       "7          HAD        NaN     167         NaN    Race      99.721105   \n",
       "8          HAM        NaN     167         NaN    Race      96.814357   \n",
       "9          HUL        NaN     167         NaN    Race      98.061882   \n",
       "10         LAW        NaN     167         NaN    Race      98.619308   \n",
       "11         LEC        NaN     167         NaN    Race            NaN   \n",
       "12         NOR        NaN     167         NaN    Race            NaN   \n",
       "13         OCO        NaN     167         NaN    Race            NaN   \n",
       "14         PIA        NaN     167         NaN    Race            NaN   \n",
       "15         RUS        NaN     167         NaN    Race            NaN   \n",
       "16         SAI        NaN     167         NaN    Race      97.149545   \n",
       "17         STR        NaN     167         NaN    Race      99.490108   \n",
       "18         TSU        NaN     167         NaN    Race     101.316667   \n",
       "19         VER        NaN     167         NaN    Race      98.001000   \n",
       "\n",
       "    std_pace_soft  laps_on_soft  deg_rate_soft  avg_pace_medium  \\\n",
       "0        4.715031            18      -0.469674        99.533585   \n",
       "1        2.682735            26      -0.088043        97.925529   \n",
       "2             NaN             0            NaN        98.304652   \n",
       "3             NaN             0            NaN        99.463955   \n",
       "4             NaN             0            NaN       101.087083   \n",
       "5        3.755982            13      -0.341254        99.005711   \n",
       "6        5.213129            10      -0.462618       100.213130   \n",
       "7        2.752830            19      -0.137761              NaN   \n",
       "8        4.200845            14      -0.093629        98.779043   \n",
       "9        6.046062            17      -0.318838        99.598708   \n",
       "10       5.122376            13      -0.841077        99.329043   \n",
       "11            NaN             0            NaN        98.476526   \n",
       "12            NaN             0            NaN        97.744958   \n",
       "13            NaN             0            NaN        99.619069   \n",
       "14            NaN             0            NaN        97.885080   \n",
       "15            NaN             0            NaN        97.405478   \n",
       "16       5.120128            11      -0.843082        99.306604   \n",
       "17       2.677640            37      -0.050600        98.429318   \n",
       "18       4.535980            12      -0.457225              NaN   \n",
       "19       1.833117            17      -0.200035              NaN   \n",
       "\n",
       "    std_pace_medium  laps_on_medium  deg_rate_medium  avg_pace_hard  \\\n",
       "0          3.187425              41        -0.072078            NaN   \n",
       "1          4.407023              34        -0.194301            NaN   \n",
       "2          2.216822              23        -0.183065      97.172278   \n",
       "3          2.736229              22        -0.144508      98.132789   \n",
       "4          4.192109              12        -0.431698      99.118170   \n",
       "5          2.517406              45        -0.022230            NaN   \n",
       "6          3.667841              23        -0.207696      99.402731   \n",
       "7               NaN               0              NaN      98.729200   \n",
       "8          2.508297              23        -0.105267      97.170800   \n",
       "9          2.762410              24        -0.118865     100.818368   \n",
       "10         2.298623              46        -0.018784            NaN   \n",
       "11         2.299503              19        -0.214341      97.487550   \n",
       "12         1.759141              24        -0.140507      96.720000   \n",
       "13         3.211223              29        -0.124563      99.447900   \n",
       "14         2.011911              25        -0.160078      96.653059   \n",
       "15         1.489478              23        -0.095824      96.797056   \n",
       "16         2.684240              48        -0.043094            NaN   \n",
       "17         3.709107              22        -0.295469            NaN   \n",
       "18              NaN               0              NaN      98.501106   \n",
       "19              NaN               0              NaN      96.750929   \n",
       "\n",
       "    std_pace_hard  laps_on_hard  deg_rate_hard  avg_pace_intermediate  \\\n",
       "0             NaN             0            NaN                    NaN   \n",
       "1             NaN             0            NaN                    NaN   \n",
       "2        3.012149            36      -0.047907                    NaN   \n",
       "3        2.906845            38      -0.103551                    NaN   \n",
       "4        3.808767            47      -0.018198                    NaN   \n",
       "5             NaN             0            NaN                    NaN   \n",
       "6        3.824296            26       0.058163                    NaN   \n",
       "7        2.958193            40      -0.066699                    NaN   \n",
       "8        4.017064            20      -0.275383                    NaN   \n",
       "9        6.393824            19       0.163630                    NaN   \n",
       "10            NaN             0            NaN                    NaN   \n",
       "11       2.885487            40      -0.004969                    NaN   \n",
       "12       2.664941            35      -0.050357                    NaN   \n",
       "13       3.214728            30      -0.066887                    NaN   \n",
       "14       3.421423            34      -0.076244                    NaN   \n",
       "15       2.798527            36      -0.055593                    NaN   \n",
       "16            NaN             0            NaN                    NaN   \n",
       "17            NaN             0            NaN                    NaN   \n",
       "18       2.907594            47      -0.040241                    NaN   \n",
       "19       2.599772            42      -0.041971                    NaN   \n",
       "\n",
       "    std_pace_intermediate  laps_on_intermediate  deg_rate_intermediate  \\\n",
       "0                     NaN                     0                    NaN   \n",
       "1                     NaN                     0                    NaN   \n",
       "2                     NaN                     0                    NaN   \n",
       "3                     NaN                     0                    NaN   \n",
       "4                     NaN                     0                    NaN   \n",
       "5                     NaN                     0                    NaN   \n",
       "6                     NaN                     0                    NaN   \n",
       "7                     NaN                     0                    NaN   \n",
       "8                     NaN                     0                    NaN   \n",
       "9                     NaN                     0                    NaN   \n",
       "10                    NaN                     0                    NaN   \n",
       "11                    NaN                     0                    NaN   \n",
       "12                    NaN                     0                    NaN   \n",
       "13                    NaN                     0                    NaN   \n",
       "14                    NaN                     0                    NaN   \n",
       "15                    NaN                     0                    NaN   \n",
       "16                    NaN                     0                    NaN   \n",
       "17                    NaN                     0                    NaN   \n",
       "18                    NaN                     0                    NaN   \n",
       "19                    NaN                     0                    NaN   \n",
       "\n",
       "    avg_pace_wet  std_pace_wet  laps_on_wet  deg_rate_wet  \n",
       "0            NaN           NaN            0           NaN  \n",
       "1            NaN           NaN            0           NaN  \n",
       "2            NaN           NaN            0           NaN  \n",
       "3            NaN           NaN            0           NaN  \n",
       "4            NaN           NaN            0           NaN  \n",
       "5            NaN           NaN            0           NaN  \n",
       "6            NaN           NaN            0           NaN  \n",
       "7            NaN           NaN            0           NaN  \n",
       "8            NaN           NaN            0           NaN  \n",
       "9            NaN           NaN            0           NaN  \n",
       "10           NaN           NaN            0           NaN  \n",
       "11           NaN           NaN            0           NaN  \n",
       "12           NaN           NaN            0           NaN  \n",
       "13           NaN           NaN            0           NaN  \n",
       "14           NaN           NaN            0           NaN  \n",
       "15           NaN           NaN            0           NaN  \n",
       "16           NaN           NaN            0           NaN  \n",
       "17           NaN           NaN            0           NaN  \n",
       "18           NaN           NaN            0           NaN  \n",
       "19           NaN           NaN            0           NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_parquet('../data/raw/fastf1/2025_Singapore_Race_laps.parquet')\n",
    "\n",
    "# Filter rows where trackstatus is 1 and both pitouttime and pitintime are NaT\n",
    "filtered_data = x[\n",
    "    (x['TrackStatus'] == '1')\n",
    "    & x['PitOutTime'].isna()\n",
    "    & x['PitInTime'].isna()\n",
    "    & x['IsAccurate'] == True\n",
    "    & (x['LapTime'] < x['LapTime'].quantile(0.95))\n",
    "].copy()\n",
    "\n",
    "filtered_data['LapTime'] = filtered_data['LapTime'].dt.total_seconds()\n",
    "\n",
    "# Load maps\n",
    "driver_id_map = pd.read_pickle('../data/raw/driver_id_map.pkl')\n",
    "race_id_map = pd.read_pickle('../data/raw/race_id_map.pkl')\n",
    "circuit_id_map = pd.read_pickle('../data/raw/circuit_id_map.pkl')\n",
    "\n",
    "# Add driver_id column\n",
    "filtered_data['driver_id'] = filtered_data['Driver'].map(\n",
    "    lambda name: driver_id_map.get(name[:3].upper(), np.nan)\n",
    ")\n",
    "\n",
    "# Add race_id and session columns\n",
    "if 'race_id' in x.columns:\n",
    "    filtered_data['race_id'] = x.loc[filtered_data.index, 'race_id']\n",
    "if 'session' in x.columns:\n",
    "    filtered_data['session'] = x.loc[filtered_data.index, 'session']\n",
    "\n",
    "# Add circuit_id column\n",
    "if 'race_id' in filtered_data.columns:\n",
    "    filtered_data['circuit_id'] = filtered_data['race_id'].map(\n",
    "        lambda rid: circuit_id_map.get(\n",
    "            ''.join([c for c in race_id_map.get(rid, '') if not c.isdigit() and c != '_']).strip(),\n",
    "            np.nan\n",
    "        ) if rid in race_id_map else np.nan\n",
    "    )\n",
    "\n",
    "# Check if we have any data after filtering\n",
    "if len(filtered_data) == 0:\n",
    "    print(\"No data found after filtering. Check your filter conditions.\")\n",
    "    print(f\"Original data shape: {x.shape}\")\n",
    "    print(f\"TrackStatus=1 count: {len(x[x['TrackStatus'] == 1])}\")\n",
    "    print(f\"PitOutTime isna count: {len(x[x['PitOutTime'].isna()])}\")\n",
    "    print(f\"PitInTime isna count: {len(x[x['PitInTime'].isna()])}\")\n",
    "else:\n",
    "    print(f\"Found {len(filtered_data)} rows after filtering\")\n",
    "\n",
    "# Helper functions for summary computation\n",
    "def get_degradation_rate(lap_times, lap_numbers):\n",
    "    if len(lap_times) > 3:\n",
    "        X = np.array(lap_numbers).reshape(-1, 1)\n",
    "        y = np.array(lap_times)\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        return model.coef_[0]\n",
    "    return np.nan\n",
    "\n",
    "def compute_compound_stats(comp_data, compound):\n",
    "    if comp_data.empty:\n",
    "        return {\n",
    "            f'avg_pace_{compound.lower()}': np.nan,\n",
    "            f'std_pace_{compound.lower()}': np.nan,\n",
    "            f'laps_on_{compound.lower()}': 0,\n",
    "            f'deg_rate_{compound.lower()}': np.nan,\n",
    "        }\n",
    "    \n",
    "    lap_times = comp_data['LapTime'].values\n",
    "    lap_numbers = comp_data['LapNumber'].values\n",
    "    \n",
    "    return {\n",
    "        f'avg_pace_{compound.lower()}': np.nanmean(lap_times),\n",
    "        f'std_pace_{compound.lower()}': np.nanstd(lap_times),\n",
    "        f'laps_on_{compound.lower()}': len(lap_times),\n",
    "        f'deg_rate_{compound.lower()}': get_degradation_rate(lap_times, lap_numbers),\n",
    "    }\n",
    "\n",
    "# Build summary dataframe\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "summaries = []\n",
    "\n",
    "for driver, group in filtered_data.groupby('Driver'):\n",
    "    summary = {'driver_name': driver}\n",
    "    \n",
    "    # Add IDs from the first row of this driver's group (same for all rows)\n",
    "    if 'driver_id' in group.columns:\n",
    "        summary['driver_id'] = group['driver_id'].iloc[0]\n",
    "    if 'race_id' in group.columns:\n",
    "        summary['race_id'] = group['race_id'].iloc[0]\n",
    "    if 'circuit_id' in group.columns:\n",
    "        summary['circuit_id'] = group['circuit_id'].iloc[0]\n",
    "    if 'session' in group.columns:\n",
    "        summary['session'] = group['session'].iloc[0]\n",
    "    \n",
    "    # Add compound-specific stats\n",
    "    for comp in compounds:\n",
    "        comp_data = group[group['Compound'] == comp]\n",
    "        summary.update(compute_compound_stats(comp_data, comp))\n",
    "    \n",
    "    summaries.append(summary)\n",
    "\n",
    "result = pd.DataFrame(summaries)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa8e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample driver names in data: ['RUS' 'VER' 'NOR' 'PIA' 'ANT']\n",
      "Sample driver_id_map keys: ['Michael Schumacher', 'David Coulthard', 'Rubens Barrichello', 'Nick Heidfeld', 'Heinz-Harald Frentzen']\n",
      "Found 1180 rows after filtering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_name</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>circuit_id</th>\n",
       "      <th>session</th>\n",
       "      <th>avg_pace_soft</th>\n",
       "      <th>std_pace_soft</th>\n",
       "      <th>laps_on_soft</th>\n",
       "      <th>deg_rate_soft</th>\n",
       "      <th>avg_pace_medium</th>\n",
       "      <th>std_pace_medium</th>\n",
       "      <th>laps_on_medium</th>\n",
       "      <th>deg_rate_medium</th>\n",
       "      <th>avg_pace_hard</th>\n",
       "      <th>std_pace_hard</th>\n",
       "      <th>laps_on_hard</th>\n",
       "      <th>deg_rate_hard</th>\n",
       "      <th>avg_pace_intermediate</th>\n",
       "      <th>std_pace_intermediate</th>\n",
       "      <th>laps_on_intermediate</th>\n",
       "      <th>deg_rate_intermediate</th>\n",
       "      <th>avg_pace_wet</th>\n",
       "      <th>std_pace_wet</th>\n",
       "      <th>laps_on_wet</th>\n",
       "      <th>deg_rate_wet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.376167</td>\n",
       "      <td>4.715031</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.469674</td>\n",
       "      <td>99.533585</td>\n",
       "      <td>3.187425</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.135769</td>\n",
       "      <td>2.682735</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.088043</td>\n",
       "      <td>97.925529</td>\n",
       "      <td>4.407023</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.194301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.304652</td>\n",
       "      <td>2.216822</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.183065</td>\n",
       "      <td>97.172278</td>\n",
       "      <td>3.012149</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.047907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.463955</td>\n",
       "      <td>2.736229</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.144508</td>\n",
       "      <td>98.132789</td>\n",
       "      <td>2.906845</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.103551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.087083</td>\n",
       "      <td>4.192109</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.431698</td>\n",
       "      <td>99.118170</td>\n",
       "      <td>3.808767</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.018198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>100.676769</td>\n",
       "      <td>3.755982</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.341254</td>\n",
       "      <td>99.005711</td>\n",
       "      <td>2.517406</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.022230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.153200</td>\n",
       "      <td>5.213129</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.462618</td>\n",
       "      <td>100.213130</td>\n",
       "      <td>3.667841</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.207696</td>\n",
       "      <td>99.402731</td>\n",
       "      <td>3.824296</td>\n",
       "      <td>26</td>\n",
       "      <td>0.058163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.721105</td>\n",
       "      <td>2.752830</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.137761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.729200</td>\n",
       "      <td>2.958193</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>96.814357</td>\n",
       "      <td>4.200845</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.093629</td>\n",
       "      <td>98.779043</td>\n",
       "      <td>2.508297</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.105267</td>\n",
       "      <td>97.170800</td>\n",
       "      <td>4.017064</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.275383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.061882</td>\n",
       "      <td>6.046062</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.318838</td>\n",
       "      <td>99.598708</td>\n",
       "      <td>2.762410</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.118865</td>\n",
       "      <td>100.818368</td>\n",
       "      <td>6.393824</td>\n",
       "      <td>19</td>\n",
       "      <td>0.163630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.619308</td>\n",
       "      <td>5.122376</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.841077</td>\n",
       "      <td>99.329043</td>\n",
       "      <td>2.298623</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.018784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.476526</td>\n",
       "      <td>2.299503</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.214341</td>\n",
       "      <td>97.487550</td>\n",
       "      <td>2.885487</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.004969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.744958</td>\n",
       "      <td>1.759141</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.140507</td>\n",
       "      <td>96.720000</td>\n",
       "      <td>2.664941</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.619069</td>\n",
       "      <td>3.211223</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.124563</td>\n",
       "      <td>99.447900</td>\n",
       "      <td>3.214728</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.066887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.885080</td>\n",
       "      <td>2.011911</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.160078</td>\n",
       "      <td>96.653059</td>\n",
       "      <td>3.421423</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.076244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.405478</td>\n",
       "      <td>1.489478</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.095824</td>\n",
       "      <td>96.797056</td>\n",
       "      <td>2.798527</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.055593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>97.149545</td>\n",
       "      <td>5.120128</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.843082</td>\n",
       "      <td>99.306604</td>\n",
       "      <td>2.684240</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.043094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>99.490108</td>\n",
       "      <td>2.677640</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.050600</td>\n",
       "      <td>98.429318</td>\n",
       "      <td>3.709107</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.295469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TSU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>101.316667</td>\n",
       "      <td>4.535980</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.457225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.501106</td>\n",
       "      <td>2.907594</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.040241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "      <td>98.001000</td>\n",
       "      <td>1.833117</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.200035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.750929</td>\n",
       "      <td>2.599772</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.041971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_name  driver_id race_id  circuit_id session  avg_pace_soft  \\\n",
       "0          ALB        NaN     167         NaN    Race      98.376167   \n",
       "1          ALO        NaN     167         NaN    Race      99.135769   \n",
       "2          ANT        NaN     167         NaN    Race            NaN   \n",
       "3          BEA        NaN     167         NaN    Race            NaN   \n",
       "4          BOR        NaN     167         NaN    Race            NaN   \n",
       "5          COL        NaN     167         NaN    Race     100.676769   \n",
       "6          GAS        NaN     167         NaN    Race      98.153200   \n",
       "7          HAD        NaN     167         NaN    Race      99.721105   \n",
       "8          HAM        NaN     167         NaN    Race      96.814357   \n",
       "9          HUL        NaN     167         NaN    Race      98.061882   \n",
       "10         LAW        NaN     167         NaN    Race      98.619308   \n",
       "11         LEC        NaN     167         NaN    Race            NaN   \n",
       "12         NOR        NaN     167         NaN    Race            NaN   \n",
       "13         OCO        NaN     167         NaN    Race            NaN   \n",
       "14         PIA        NaN     167         NaN    Race            NaN   \n",
       "15         RUS        NaN     167         NaN    Race            NaN   \n",
       "16         SAI        NaN     167         NaN    Race      97.149545   \n",
       "17         STR        NaN     167         NaN    Race      99.490108   \n",
       "18         TSU        NaN     167         NaN    Race     101.316667   \n",
       "19         VER        NaN     167         NaN    Race      98.001000   \n",
       "\n",
       "    std_pace_soft  laps_on_soft  deg_rate_soft  avg_pace_medium  \\\n",
       "0        4.715031            18      -0.469674        99.533585   \n",
       "1        2.682735            26      -0.088043        97.925529   \n",
       "2             NaN             0            NaN        98.304652   \n",
       "3             NaN             0            NaN        99.463955   \n",
       "4             NaN             0            NaN       101.087083   \n",
       "5        3.755982            13      -0.341254        99.005711   \n",
       "6        5.213129            10      -0.462618       100.213130   \n",
       "7        2.752830            19      -0.137761              NaN   \n",
       "8        4.200845            14      -0.093629        98.779043   \n",
       "9        6.046062            17      -0.318838        99.598708   \n",
       "10       5.122376            13      -0.841077        99.329043   \n",
       "11            NaN             0            NaN        98.476526   \n",
       "12            NaN             0            NaN        97.744958   \n",
       "13            NaN             0            NaN        99.619069   \n",
       "14            NaN             0            NaN        97.885080   \n",
       "15            NaN             0            NaN        97.405478   \n",
       "16       5.120128            11      -0.843082        99.306604   \n",
       "17       2.677640            37      -0.050600        98.429318   \n",
       "18       4.535980            12      -0.457225              NaN   \n",
       "19       1.833117            17      -0.200035              NaN   \n",
       "\n",
       "    std_pace_medium  laps_on_medium  deg_rate_medium  avg_pace_hard  \\\n",
       "0          3.187425              41        -0.072078            NaN   \n",
       "1          4.407023              34        -0.194301            NaN   \n",
       "2          2.216822              23        -0.183065      97.172278   \n",
       "3          2.736229              22        -0.144508      98.132789   \n",
       "4          4.192109              12        -0.431698      99.118170   \n",
       "5          2.517406              45        -0.022230            NaN   \n",
       "6          3.667841              23        -0.207696      99.402731   \n",
       "7               NaN               0              NaN      98.729200   \n",
       "8          2.508297              23        -0.105267      97.170800   \n",
       "9          2.762410              24        -0.118865     100.818368   \n",
       "10         2.298623              46        -0.018784            NaN   \n",
       "11         2.299503              19        -0.214341      97.487550   \n",
       "12         1.759141              24        -0.140507      96.720000   \n",
       "13         3.211223              29        -0.124563      99.447900   \n",
       "14         2.011911              25        -0.160078      96.653059   \n",
       "15         1.489478              23        -0.095824      96.797056   \n",
       "16         2.684240              48        -0.043094            NaN   \n",
       "17         3.709107              22        -0.295469            NaN   \n",
       "18              NaN               0              NaN      98.501106   \n",
       "19              NaN               0              NaN      96.750929   \n",
       "\n",
       "    std_pace_hard  laps_on_hard  deg_rate_hard  avg_pace_intermediate  \\\n",
       "0             NaN             0            NaN                    NaN   \n",
       "1             NaN             0            NaN                    NaN   \n",
       "2        3.012149            36      -0.047907                    NaN   \n",
       "3        2.906845            38      -0.103551                    NaN   \n",
       "4        3.808767            47      -0.018198                    NaN   \n",
       "5             NaN             0            NaN                    NaN   \n",
       "6        3.824296            26       0.058163                    NaN   \n",
       "7        2.958193            40      -0.066699                    NaN   \n",
       "8        4.017064            20      -0.275383                    NaN   \n",
       "9        6.393824            19       0.163630                    NaN   \n",
       "10            NaN             0            NaN                    NaN   \n",
       "11       2.885487            40      -0.004969                    NaN   \n",
       "12       2.664941            35      -0.050357                    NaN   \n",
       "13       3.214728            30      -0.066887                    NaN   \n",
       "14       3.421423            34      -0.076244                    NaN   \n",
       "15       2.798527            36      -0.055593                    NaN   \n",
       "16            NaN             0            NaN                    NaN   \n",
       "17            NaN             0            NaN                    NaN   \n",
       "18       2.907594            47      -0.040241                    NaN   \n",
       "19       2.599772            42      -0.041971                    NaN   \n",
       "\n",
       "    std_pace_intermediate  laps_on_intermediate  deg_rate_intermediate  \\\n",
       "0                     NaN                     0                    NaN   \n",
       "1                     NaN                     0                    NaN   \n",
       "2                     NaN                     0                    NaN   \n",
       "3                     NaN                     0                    NaN   \n",
       "4                     NaN                     0                    NaN   \n",
       "5                     NaN                     0                    NaN   \n",
       "6                     NaN                     0                    NaN   \n",
       "7                     NaN                     0                    NaN   \n",
       "8                     NaN                     0                    NaN   \n",
       "9                     NaN                     0                    NaN   \n",
       "10                    NaN                     0                    NaN   \n",
       "11                    NaN                     0                    NaN   \n",
       "12                    NaN                     0                    NaN   \n",
       "13                    NaN                     0                    NaN   \n",
       "14                    NaN                     0                    NaN   \n",
       "15                    NaN                     0                    NaN   \n",
       "16                    NaN                     0                    NaN   \n",
       "17                    NaN                     0                    NaN   \n",
       "18                    NaN                     0                    NaN   \n",
       "19                    NaN                     0                    NaN   \n",
       "\n",
       "    avg_pace_wet  std_pace_wet  laps_on_wet  deg_rate_wet  \n",
       "0            NaN           NaN            0           NaN  \n",
       "1            NaN           NaN            0           NaN  \n",
       "2            NaN           NaN            0           NaN  \n",
       "3            NaN           NaN            0           NaN  \n",
       "4            NaN           NaN            0           NaN  \n",
       "5            NaN           NaN            0           NaN  \n",
       "6            NaN           NaN            0           NaN  \n",
       "7            NaN           NaN            0           NaN  \n",
       "8            NaN           NaN            0           NaN  \n",
       "9            NaN           NaN            0           NaN  \n",
       "10           NaN           NaN            0           NaN  \n",
       "11           NaN           NaN            0           NaN  \n",
       "12           NaN           NaN            0           NaN  \n",
       "13           NaN           NaN            0           NaN  \n",
       "14           NaN           NaN            0           NaN  \n",
       "15           NaN           NaN            0           NaN  \n",
       "16           NaN           NaN            0           NaN  \n",
       "17           NaN           NaN            0           NaN  \n",
       "18           NaN           NaN            0           NaN  \n",
       "19           NaN           NaN            0           NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = pd.read_parquet('../data/raw/fastf1/2025_Singapore_Race_laps.parquet')\n",
    "\n",
    "# Filter rows where trackstatus is 1 and both pitouttime and pitintime are NaT\n",
    "filtered_data = x[\n",
    "    (x['TrackStatus'] == '1')\n",
    "    & x['PitOutTime'].isna()\n",
    "    & x['PitInTime'].isna()\n",
    "    & x['IsAccurate'] == True\n",
    "    & (x['LapTime'] < x['LapTime'].quantile(0.95))\n",
    "].copy()\n",
    "\n",
    "filtered_data['LapTime'] = filtered_data['LapTime'].dt.total_seconds()\n",
    "\n",
    "# Load maps\n",
    "driver_id_map = pd.read_pickle('../data/raw/driver_id_map.pkl')\n",
    "race_id_map = pd.read_pickle('../data/raw/race_id_map.pkl')\n",
    "circuit_id_map = pd.read_pickle('../data/raw/circuit_id_map.pkl')\n",
    "\n",
    "# Debug: Check what we have\n",
    "print(\"Sample driver names in data:\", filtered_data['Driver'].unique()[:5])\n",
    "print(\"Sample driver_id_map keys:\", list(driver_id_map.keys())[:5])\n",
    "\n",
    "# Add driver_id column - try exact match first, then fuzzy matching if needed\n",
    "filtered_data['driver_id'] = filtered_data['Driver'].map(\n",
    "    lambda name: driver_id_map.get(name, np.nan)\n",
    ")\n",
    "\n",
    "# Add race_id and session columns\n",
    "if 'race_id' in x.columns:\n",
    "    filtered_data['race_id'] = x.loc[filtered_data.index, 'race_id']\n",
    "if 'session' in x.columns:\n",
    "    filtered_data['session'] = x.loc[filtered_data.index, 'session']\n",
    "\n",
    "# Add circuit_id column\n",
    "if 'race_id' in filtered_data.columns:\n",
    "    filtered_data['circuit_id'] = filtered_data['race_id'].map(\n",
    "        lambda rid: circuit_id_map.get(\n",
    "            ''.join([c for c in race_id_map.get(rid, '') if not c.isdigit() and c != '_']).strip(),\n",
    "            np.nan\n",
    "        ) if rid in race_id_map else np.nan\n",
    "    )\n",
    "\n",
    "# Check if we have any data after filtering\n",
    "if len(filtered_data) == 0:\n",
    "    print(\"No data found after filtering. Check your filter conditions.\")\n",
    "    print(f\"Original data shape: {x.shape}\")\n",
    "    print(f\"TrackStatus=1 count: {len(x[x['TrackStatus'] == 1])}\")\n",
    "    print(f\"PitOutTime isna count: {len(x[x['PitOutTime'].isna()])}\")\n",
    "    print(f\"PitInTime isna count: {len(x[x['PitInTime'].isna()])}\")\n",
    "else:\n",
    "    print(f\"Found {len(filtered_data)} rows after filtering\")\n",
    "\n",
    "# Helper functions for summary computation\n",
    "def get_degradation_rate(lap_times, lap_numbers):\n",
    "    if len(lap_times) > 3:\n",
    "        X = np.array(lap_numbers).reshape(-1, 1)\n",
    "        y = np.array(lap_times)\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        return model.coef_[0]\n",
    "    return np.nan\n",
    "\n",
    "def compute_compound_stats(comp_data, compound):\n",
    "    if comp_data.empty:\n",
    "        return {\n",
    "            f'avg_pace_{compound.lower()}': np.nan,\n",
    "            f'std_pace_{compound.lower()}': np.nan,\n",
    "            f'laps_on_{compound.lower()}': 0,\n",
    "            f'deg_rate_{compound.lower()}': np.nan,\n",
    "        }\n",
    "    \n",
    "    lap_times = comp_data['LapTime'].values\n",
    "    lap_numbers = comp_data['LapNumber'].values\n",
    "    \n",
    "    return {\n",
    "        f'avg_pace_{compound.lower()}': np.nanmean(lap_times),\n",
    "        f'std_pace_{compound.lower()}': np.nanstd(lap_times),\n",
    "        f'laps_on_{compound.lower()}': len(lap_times),\n",
    "        f'deg_rate_{compound.lower()}': get_degradation_rate(lap_times, lap_numbers),\n",
    "    }\n",
    "\n",
    "# Build summary dataframe\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "summaries = []\n",
    "\n",
    "for driver, group in filtered_data.groupby('Driver'):\n",
    "    summary = {'driver_name': driver}\n",
    "    \n",
    "    # Add IDs from the first row of this driver's group (same for all rows)\n",
    "    if 'driver_id' in group.columns:\n",
    "        summary['driver_id'] = group['driver_id'].iloc[0]\n",
    "    if 'race_id' in group.columns:\n",
    "        summary['race_id'] = group['race_id'].iloc[0]\n",
    "    if 'circuit_id' in group.columns:\n",
    "        summary['circuit_id'] = group['circuit_id'].iloc[0]\n",
    "    if 'session' in group.columns:\n",
    "        summary['session'] = group['session'].iloc[0]\n",
    "    \n",
    "    # Add compound-specific stats\n",
    "    for comp in compounds:\n",
    "        comp_data = group[group['Compound'] == comp]\n",
    "        summary.update(compute_compound_stats(comp_data, comp))\n",
    "    \n",
    "    summaries.append(summary)\n",
    "\n",
    "result = pd.DataFrame(summaries)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0458d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Michael Schumacher': 1,\n",
       " 'David Coulthard': 2,\n",
       " 'Rubens Barrichello': 3,\n",
       " 'Nick Heidfeld': 4,\n",
       " 'Heinz-Harald Frentzen': 5,\n",
       " 'Kimi Räikkönen': 6,\n",
       " 'Olivier Panis': 7,\n",
       " 'Luciano Burti': 8,\n",
       " 'Jean Alesi': 9,\n",
       " 'Jos Verstappen': 10,\n",
       " 'Eddie Irvine': 11,\n",
       " 'Fernando Alonso': 12,\n",
       " 'Giancarlo Fisichella': 13,\n",
       " 'Jenson Button': 14,\n",
       " 'Juan Pablo Montoya': 15,\n",
       " 'Jarno Trulli': 16,\n",
       " 'Mika Hakkinen': 17,\n",
       " 'Ralf Schumacher': 18,\n",
       " 'Jacques Villeneuve': 19,\n",
       " 'Tarso Marques': 20,\n",
       " 'Enrique Bernoldi': 21,\n",
       " 'Gaston Mazzacane': 22,\n",
       " 'Pedro de la Rosa': 23,\n",
       " 'Ricardo Zonta': 24,\n",
       " 'Tomas Enge': 25,\n",
       " 'Alex Yoong': 26,\n",
       " 'Mark Webber': 27,\n",
       " 'Mika Salo': 28,\n",
       " 'Takuma Sato': 29,\n",
       " 'Felipe Massa': 30,\n",
       " 'Allan McNish': 31,\n",
       " 'Anthony Davidson': 32,\n",
       " 'Antonio Pizzonia': 33,\n",
       " 'Justin Wilson': 34,\n",
       " 'Cristiano da Matta': 35,\n",
       " 'Ralph Firman': 36,\n",
       " 'Nicolas Kiesa': 37,\n",
       " 'Zsolt Baumgartner': 38,\n",
       " 'Marc Gene': 39,\n",
       " 'Christian Klien': 40,\n",
       " 'Giorgio Pantano': 41,\n",
       " 'Gianmaria Bruni': 42,\n",
       " 'Timo Glock': 43,\n",
       " 'Narain Karthikeyan': 44,\n",
       " 'Tiago Monteiro': 45,\n",
       " 'Patrick Friesacher': 46,\n",
       " 'Christijan Albers': 47,\n",
       " 'Alexander Wurz': 48,\n",
       " 'Vitantonio Liuzzi': 49,\n",
       " 'Robert Doornbos': 50,\n",
       " 'Nico Rosberg': 51,\n",
       " 'Scott Speed': 52,\n",
       " 'Yuji Ide': 53,\n",
       " 'Franck Montagny': 54,\n",
       " 'Sakon Yamamoto': 55,\n",
       " 'Robert Kubica': 56,\n",
       " 'Lewis Hamilton': 57,\n",
       " 'Heikki Kovalainen': 58,\n",
       " 'Adrian Sutil': 59,\n",
       " 'Sebastian Vettel': 60,\n",
       " 'Markus Winkelhock': 61,\n",
       " 'Kazuki Nakajima': 62,\n",
       " 'Sebastien Bourdais': 63,\n",
       " 'Nelson Piquet': 64,\n",
       " 'Sebastien Buemi': 65,\n",
       " 'Jaime Alguersuari': 66,\n",
       " 'Romain Grosjean': 67,\n",
       " 'Luca Badoer': 68,\n",
       " 'Kamui Kobayashi': 69,\n",
       " 'Nico Hulkenberg': 70,\n",
       " 'Bruno Senna': 71,\n",
       " 'Vitaly Petrov': 72,\n",
       " 'Lucas di Grassi': 73,\n",
       " 'Karun Chandhok': 74,\n",
       " 'Sergio Perez': 75,\n",
       " 'Paul di Resta': 76,\n",
       " \"Jerome d'Ambrosio\": 77,\n",
       " 'Pastor Maldonado': 78,\n",
       " 'Daniel Ricciardo': 79,\n",
       " 'Jean-Eric Vergne': 80,\n",
       " 'Charles Pic': 81,\n",
       " 'Esteban Gutierrez': 82,\n",
       " 'Valtteri Bottas': 83,\n",
       " 'Jules Bianchi': 84,\n",
       " 'Max Chilton': 85,\n",
       " 'Giedo van der Garde': 86,\n",
       " 'Kevin Magnussen': 87,\n",
       " 'Daniil Kvyat': 88,\n",
       " 'Marcus Ericsson': 89,\n",
       " 'Andre Lotterer': 90,\n",
       " 'Will Stevens': 91,\n",
       " 'Felipe Nasr': 92,\n",
       " 'Carlos Sainz': 93,\n",
       " 'Max Verstappen': 94,\n",
       " 'Roberto Merhi': 95,\n",
       " 'Alexander Rossi': 96,\n",
       " 'Jolyon Palmer': 97,\n",
       " 'Pascal Wehrlein': 98,\n",
       " 'Rio Haryanto': 99,\n",
       " 'Stoffel Vandoorne': 100,\n",
       " 'Esteban Ocon': 101,\n",
       " 'Antonio Giovinazzi': 102,\n",
       " 'Lance Stroll': 103,\n",
       " 'Pierre Gasly': 104,\n",
       " 'Brendon Hartley': 105,\n",
       " 'Charles Leclerc': 106,\n",
       " 'Sergey Sirotkin': 107,\n",
       " 'Lando Norris': 108,\n",
       " 'Alexander Albon': 109,\n",
       " 'George Russell': 110,\n",
       " 'Nicholas Latifi': 111,\n",
       " 'Jack Aitken': 112,\n",
       " 'Pietro Fittipaldi': 113,\n",
       " 'Yuki Tsunoda': 114,\n",
       " 'Mick Schumacher': 115,\n",
       " 'Nikita Mazepin': 116,\n",
       " 'Zhou Guanyu': 117,\n",
       " 'Nyck De Vries': 118,\n",
       " 'Logan Sargeant': 119,\n",
       " 'Oscar Piastri': 120,\n",
       " 'Liam Lawson': 121,\n",
       " 'Oliver Bearman': 122,\n",
       " 'Franco Colapinto': 123,\n",
       " 'Jack Doohan': 124,\n",
       " 'Kimi Antonelli': 125,\n",
       " 'Gabriel Bortoleto': 126,\n",
       " 'Isack Hadjar': 127,\n",
       " 'Artem Markelov': 128,\n",
       " 'Sean Gelael': 129,\n",
       " 'Naoki Yamamoto': 130,\n",
       " 'Roy Nissany': 131,\n",
       " 'Callum Ilott': 132,\n",
       " 'Juri Vips': 133,\n",
       " 'Robert Shwartzman': 134,\n",
       " 'Alex Palou': 135,\n",
       " 'Theo Pourchaire': 136,\n",
       " \"Patricio O'Ward\": 137,\n",
       " 'Felipe Drugovich': 138,\n",
       " 'Frederik Vesti': 139,\n",
       " 'Jake Dennis': 140,\n",
       " \"Zak O'Sullivan\": 141,\n",
       " 'Ayumu Iwasa': 142,\n",
       " 'Ryo Hirakawa': 143,\n",
       " 'Arthur Leclerc': 144,\n",
       " 'Luke Browning': 145,\n",
       " 'Dino Beganovic': 146,\n",
       " 'Victor Martins': 147,\n",
       " 'Alexander Dunne': 148,\n",
       " 'Arvid Lindblad': 149,\n",
       " 'Paul Aron': 150}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = load_id_map('../data/raw/driver_id_map.pkl')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00569f46",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c523242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing race 1/167: 2018 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 2/167: 2018 Bahrain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 3/167: 2018 China\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 4/167: 2018 Azerbaijan\n"
     ]
    }
   ],
   "source": [
    "# Initialize urls and sessions\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "sessions_collected = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "fastf1.Cache.disabled = True\n",
    "\n",
    "# Suppress FastF1 logging output\n",
    "fastf1_logger = logging.getLogger('fastf1')\n",
    "fastf1_logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "# Initialize empty DataFrames to collect all data\n",
    "all_laps = pd.DataFrame()\n",
    "all_weather = pd.DataFrame()\n",
    "all_messages = pd.DataFrame()\n",
    "\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for url_idx, url in enumerate(urls):\n",
    "    \n",
    "    # Sort year and grand prix from the url\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = url.split('/')[8].replace('-', ' ').title().replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    \n",
    "    print(f\"\\nProcessing race {url_idx + 1}/{len(urls)}: {year} {gp}\")\n",
    "    \n",
    "    for s in sessions_collected:\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        success = False\n",
    "        \n",
    "        laps_df = None\n",
    "        weather_df = None\n",
    "        messages_df = None\n",
    "        session = None\n",
    "\n",
    "        # Load session with retry\n",
    "        while retry_count < max_retries and not success:\n",
    "            try:\n",
    "                gc.collect()\n",
    "                \n",
    "                session = fastf1.get_session(year, gp, s)\n",
    "                if retry_count > 0:\n",
    "                    time.sleep(3)\n",
    "                session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "                \n",
    "                # Extract data with error handling\n",
    "                try:\n",
    "                    laps_df = session.laps.copy() if hasattr(session, 'laps') and session.laps is not None else None\n",
    "                except:\n",
    "                    laps_df = None\n",
    "                try:\n",
    "                    weather_df = pd.DataFrame(session.weather_data) if hasattr(session, 'weather_data') and session.weather_data is not None else None\n",
    "                except:\n",
    "                    weather_df = None\n",
    "                try:\n",
    "                    messages_df = pd.DataFrame(session.race_control_messages) if hasattr(session, 'race_control_messages') and session.race_control_messages is not None else None\n",
    "                except:\n",
    "                    messages_df = None\n",
    "                \n",
    "                success = True\n",
    "                print(f\"  Loaded {s}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count < max_retries:\n",
    "                    sleep_time = 2 ** retry_count\n",
    "                    print(f'  Retry {retry_count}/{max_retries} for {year} {gp} {s}: {e}. Sleeping for {sleep_time}s...')\n",
    "                    time.sleep(sleep_time)\n",
    "                else:\n",
    "                    print(f'  Failed after {max_retries} retries for {year} {gp} {s}: {e}')\n",
    "            \n",
    "            finally:\n",
    "                # Delete session object immediately to release resources\n",
    "                if session is not None:\n",
    "                    del session\n",
    "                gc.collect()\n",
    "        \n",
    "        if not success:\n",
    "            continue\n",
    "        \n",
    "        # Get race ID\n",
    "        race_key = f'{gp}_{year}'\n",
    "        race_id_value = race_id_map.get(race_key)\n",
    "        if race_id_value is None:\n",
    "            print(f'  Warning: No race_id found for: {race_key}')\n",
    "        \n",
    "        # Add race_id and session columns to each DataFrame and merge\n",
    "        if laps_df is not None and not laps_df.empty:\n",
    "            laps_df['race_id'] = race_id_value\n",
    "            laps_df['session'] = s\n",
    "            all_laps = pd.concat([all_laps, laps_df], ignore_index=True)\n",
    "        if weather_df is not None and not weather_df.empty:\n",
    "            weather_df['race_id'] = race_id_value\n",
    "            weather_df['session'] = s\n",
    "            all_weather = pd.concat([all_weather, weather_df], ignore_index=True)\n",
    "        if messages_df is not None and not messages_df.empty:\n",
    "            messages_df['race_id'] = race_id_value\n",
    "            messages_df['session'] = s\n",
    "            all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n",
    "\n",
    "        # Clean up DataFrames after each session\n",
    "        del laps_df, weather_df, messages_df\n",
    "    \n",
    "    # Force garbage collection after each race\n",
    "    gc.collect()\n",
    "    \n",
    "    # Save intermediate results every 5 races\n",
    "    if (url_idx + 1) % 5 == 0:\n",
    "        print(f\"Saving intermediate results after race {url_idx + 1}...\")\n",
    "        all_laps.to_csv('../data/raw/lap_data_raw_temp.csv', index=False)\n",
    "        all_weather.to_csv('../data/raw/weather_data_raw_temp.csv', index=False)\n",
    "        all_messages.to_csv('../data/raw/messages_data_raw_temp.csv', index=False)\n",
    "        print(f\"  Saved: {len(all_laps)} laps, {len(all_weather)} weather records, {len(all_messages)} messages\")\n",
    "    \n",
    "# Save final DataFrames to CSVs\n",
    "all_laps.to_csv('../data/raw/lap_data_raw.csv', index=False)\n",
    "all_weather.to_csv('../data/raw/weather_data_raw.csv', index=False)\n",
    "all_messages.to_csv('../data/raw/messages_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3c5d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1/167 | 2018 Australia ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 82\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Launch a new Python process for this race\u001b[39;00m\n\u001b[0;32m     81\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m---> 82\u001b[0m     [sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;18;43m__file__\u001b[39;49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--race\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(year), gp, \u001b[38;5;28mstr\u001b[39m(race_id_value), CACHE_DIR, OUTPUT_DIR],\n\u001b[0;32m     83\u001b[0m     check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Pause briefly between races\u001b[39;00m\n\u001b[0;32m     87\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "# If we're inside a subprocess, these will be passed in as args\n",
    "if len(sys.argv) > 1 and sys.argv[1] == \"--race\":\n",
    "    # Subprocess mode: handle a single race\n",
    "    year = int(sys.argv[2])\n",
    "    gp = sys.argv[3]\n",
    "    race_id_value = sys.argv[4]\n",
    "    cache_dir = sys.argv[5]\n",
    "    output_dir = sys.argv[6]\n",
    "\n",
    "    sessions = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "    fastf1.Cache.enable_cache(cache_dir)\n",
    "\n",
    "    for s in sessions:\n",
    "        try:\n",
    "            gc.collect()\n",
    "            session = fastf1.get_session(year, gp, s)\n",
    "            session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "            print(f\" Loaded {year} {gp} {s}\")\n",
    "\n",
    "            # Extract safely\n",
    "            laps = getattr(session, 'laps', pd.DataFrame())\n",
    "            weather = getattr(session, 'weather_data', pd.DataFrame())\n",
    "            messages = getattr(session, 'race_control_messages', pd.DataFrame())\n",
    "\n",
    "            for df in [laps, weather, messages]:\n",
    "                if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                    df[\"race_id\"] = race_id_value\n",
    "                    df[\"session\"] = s\n",
    "\n",
    "            # Save\n",
    "            prefix = f\"{output_dir}/{year}_{gp}_{s}\"\n",
    "            if not laps.empty:\n",
    "                laps.to_parquet(f\"{prefix}_laps.parquet\")\n",
    "            if not weather.empty:\n",
    "                weather.to_parquet(f\"{prefix}_weather.parquet\")\n",
    "            if not messages.empty:\n",
    "                messages.to_parquet(f\"{prefix}_messages.parquet\")\n",
    "\n",
    "            print(f\" Saved {year} {gp} {s}\")\n",
    "            del session\n",
    "            gc.collect()\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error for {year} {gp} {s}: {e}\")\n",
    "            time.sleep(3)\n",
    "    sys.exit(0)\n",
    "\n",
    "# === Main controller ===\n",
    "CACHE_DIR = \"../data/cache\"\n",
    "OUTPUT_DIR = \"../data/raw/fastf1\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = (\n",
    "        url.split('/')[8]\n",
    "        .replace('-', ' ')\n",
    "        .title()\n",
    "        .replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    )\n",
    "    race_key = f\"{gp}_{year}\"\n",
    "    race_id_value = race_id_map.get(race_key, \"unknown\")\n",
    "\n",
    "    print(f\"\\n=== {idx+1}/{len(urls)} | {year} {gp} ===\")\n",
    "\n",
    "    # Launch a new Python process for this race\n",
    "    subprocess.run(\n",
    "        [sys.executable, __file__, \"--race\", str(year), gp, str(race_id_value), CACHE_DIR, OUTPUT_DIR],\n",
    "        check=False,\n",
    "    )\n",
    "\n",
    "    # Pause briefly between races\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53932cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing race 1/167: 2018 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 2/167: 2018 Bahrain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 3/167: 2018 China\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 4/167: 2018 Azerbaijan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 5/167: 2018 Spain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 5...\n",
      "  Saved: 13193 laps, 2186 weather records, 1001 messages\n",
      "\n",
      "Processing race 6/167: 2018 Monaco\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 7/167: 2018 Canada\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 8/167: 2018 France\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 9/167: 2018 Austria\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 10/167: 2018 Great Britain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 10...\n",
      "  Saved: 28484 laps, 4367 weather records, 1925 messages\n",
      "\n",
      "Processing race 11/167: 2018 Germany\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 12/167: 2018 Hungary\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 13/167: 2018 Belgium\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 14/167: 2018 Italy\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 15/167: 2018 Singapore\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 15...\n",
      "  Saved: 42036 laps, 6709 weather records, 2666 messages\n",
      "\n",
      "Processing race 16/167: 2018 Russia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 17/167: 2018 Japan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 18/167: 2018 United States\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 19/167: 2018 Mexico\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 20/167: 2018 Brazil\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 20...\n",
      "  Saved: 55359 laps, 9187 weather records, 3459 messages\n",
      "\n",
      "Processing race 21/167: 2018 Abu Dhabi\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 22/167: 2019 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 23/167: 2019 Bahrain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 24/167: 2019 China\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 25/167: 2019 Azerbaijan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 25...\n",
      "  Saved: 68148 laps, 11698 weather records, 4273 messages\n",
      "\n",
      "Processing race 26/167: 2019 Spain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 27/167: 2019 Monaco\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 28/167: 2019 Canada\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 29/167: 2019 France\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 30/167: 2019 Austria\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intermediate results after race 30...\n",
      "  Saved: 84657 laps, 14213 weather records, 5178 messages\n",
      "\n",
      "Processing race 31/167: 2019 Great Britain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 32/167: 2019 Germany\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 33/167: 2019 Hungary\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 34/167: 2019 Belgium\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 35/167: 2019 Italy\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 35...\n",
      "  Saved: 97870 laps, 16744 weather records, 6032 messages\n",
      "\n",
      "Processing race 36/167: 2019 Singapore\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 37/167: 2019 Russia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 38/167: 2019 Japan\n",
      "  Loaded FP1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 39/167: 2019 Mexico\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 40/167: 2019 United States\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 40...\n",
      "  Saved: 110061 laps, 19022 weather records, 6843 messages\n",
      "\n",
      "Processing race 41/167: 2019 Brazil\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 42/167: 2019 Abu Dhabi\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 43/167: 2020 Austria\n",
      "  Retry 1/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP1: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP2: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP3: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria Qualifying: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria Race: Failed to load any schedule data.\n",
      "\n",
      "Processing race 44/167: 2020 Styria\n",
      "  Retry 1/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 8s...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m---> 46\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mfastf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     session\u001b[38;5;241m.\u001b[39mload(laps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, telemetry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, weather\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Extract data with error handling\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:310\u001b[0m, in \u001b[0;36mget_session\u001b[1;34m(year, gp, identifier, backend, force_ergast)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_session\u001b[39m(\n\u001b[0;32m    243\u001b[0m         year: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    244\u001b[0m         gp: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m         force_ergast: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    249\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Session:\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a :class:`~fastf1.core.Session` object based on year, event name\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    and session identifier.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m            from the ergast database to create the event schedule\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[43mget_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ergast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ergast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m event\u001b[38;5;241m.\u001b[39mget_session(identifier)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:405\u001b[0m, in \u001b[0;36mget_event\u001b[1;34m(year, gp, backend, force_ergast, strict_search, exact_match)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_event\u001b[39m(\n\u001b[0;32m    351\u001b[0m         year: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    352\u001b[0m         gp: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m         exact_match: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an :class:`~fastf1.events.Event` object for a specific\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    season and gp.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.2\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     schedule \u001b[38;5;241m=\u001b[39m \u001b[43mget_event_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mforce_ergast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ergast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    410\u001b[0m         event \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39mget_event_by_name(\n\u001b[0;32m    411\u001b[0m             gp, strict_search\u001b[38;5;241m=\u001b[39mstrict_search, exact_match\u001b[38;5;241m=\u001b[39mexact_match)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:517\u001b[0m, in \u001b[0;36mget_event_schedule\u001b[1;34m(year, include_testing, backend, force_ergast)\u001b[0m\n\u001b[0;32m    515\u001b[0m schedule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m--> 517\u001b[0m     schedule \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schedule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\logger.py:151\u001b[0m, in \u001b[0;36msoft_exceptions.<locals>.__decorator.<locals>.__wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LoggingManager\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    153\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:659\u001b[0m, in \u001b[0;36m_get_schedule_from_f1_timing\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;129m@soft_exceptions\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 API schedule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    655\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load schedule from F1 API backend!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    656\u001b[0m                  _logger)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_schedule_from_f1_timing\u001b[39m(year: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# create an event schedule using data from the F1 API\u001b[39;00m\n\u001b[1;32m--> 659\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfastf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseason_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/static/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     data \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:479\u001b[0m, in \u001b[0;36mCache.api_request_wrapper.<locals>._cached_api_request\u001b[1;34m(api_path, **func_kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# cached data does not yet exist for this api request\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo cached data found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    478\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 479\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_write_cache(data, cache_file_path)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\_api.py:1678\u001b[0m, in \u001b[0;36mseason_schedule\u001b[1;34m(path, response)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1677\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching season schedule...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1678\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# no response received\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SessionNotAvailableError(\n\u001b[0;32m   1681\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data for this session! If this session only finished \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1682\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecently, please try again in a few minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1683\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\_api.py:1752\u001b[0m, in \u001b[0;36mfetch_page\u001b[1;34m(path, name)\u001b[0m\n\u001b[0;32m   1749\u001b[0m is_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjsonStream\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m page\n\u001b[0;32m   1750\u001b[0m is_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.z.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m page\n\u001b[1;32m-> 1752\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mCache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m   1755\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to livetiming mirror (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url_mirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:303\u001b[0m, in \u001b[0;36mCache.requests_get\u001b[1;34m(cls, url, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_request_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:347\u001b[0m, in \u001b[0;36mCache._cached_request\u001b[1;34m(cls, method, url, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# catch TypeError raised by outdated requests-cache version if the\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# cache was created with a newer version\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# github.com/requests-cache/requests-cache/issues/973\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using an outdated version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequests-cache. Consider upgrading.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:127\u001b[0m, in \u001b[0;36mCacheMixin.get\u001b[1;34m(self, url, params, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyResponse:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:183\u001b[0m, in \u001b[0;36mCacheMixin.request\u001b[1;34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m headers \u001b[38;5;241m=\u001b[39m set_request_headers(headers, expire_after, only_if_cached, refresh, force_refresh)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch_form_boundary() \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:230\u001b[0m, in \u001b[0;36mCacheMixin.send\u001b[1;34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resend(request, actions, cached_response, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m actions\u001b[38;5;241m.\u001b[39msend_request:\n\u001b[1;32m--> 230\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     response \u001b[38;5;241m=\u001b[39m cached_response  \u001b[38;5;66;03m# type: ignore  # Guaranteed to be non-None by this point\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:254\u001b[0m, in \u001b[0;36mCacheMixin._send_and_cache\u001b[1;34m(self, request, actions, cached_response, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a request and cache the response, unless disabled by settings or headers.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03mIf applicable, also handle conditional requests.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    253\u001b[0m request \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mupdate_request(request)\n\u001b[1;32m--> 254\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m actions\u001b[38;5;241m.\u001b[39mupdate_from_response(response)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions\u001b[38;5;241m.\u001b[39mskip_write:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:134\u001b[0m, in \u001b[0;36m_SessionWithRateLimiting.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pattern\u001b[38;5;241m.\u001b[39mmatch(request\u001b[38;5;241m.\u001b[39murl):\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lim \u001b[38;5;129;01min\u001b[39;00m limiters:\n\u001b[0;32m    133\u001b[0m             \u001b[38;5;66;03m# apply all defined limiters\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m             \u001b[43mlim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:83\u001b[0m, in \u001b[0;36m_MinIntervalLimitDelay.limit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m t_now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (delta \u001b[38;5;241m:=\u001b[39m (t_now \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t_last)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interval:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     t_now \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interval \u001b[38;5;241m-\u001b[39m delta\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t_last \u001b[38;5;241m=\u001b[39m t_now\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Initialize urls and sessions\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "sessions_collected = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "fastf1.Cache.disabled = True\n",
    "\n",
    "# Suppress FastF1 logging output\n",
    "fastf1_logger = logging.getLogger('fastf1')\n",
    "fastf1_logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "# Initialize empty DataFrames to collect all data\n",
    "all_laps = pd.DataFrame()\n",
    "all_weather = pd.DataFrame()\n",
    "all_messages = pd.DataFrame()\n",
    "\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for url_idx, url in enumerate(urls):\n",
    "    \n",
    "    # Sort year and grand prix from the url\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = url.split('/')[8].replace('-', ' ').title().replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    \n",
    "    print(f\"\\nProcessing race {url_idx + 1}/{len(urls)}: {year} {gp}\")\n",
    "    \n",
    "    for s in sessions_collected:\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        success = False\n",
    "        \n",
    "        laps_df = None\n",
    "        weather_df = None\n",
    "        messages_df = None\n",
    "        session = None\n",
    "\n",
    "        # Load session with retry\n",
    "        while retry_count < max_retries and not success:\n",
    "            try:\n",
    "                gc.collect()\n",
    "                \n",
    "                session = fastf1.get_session(year, gp, s)\n",
    "                session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "                \n",
    "                # Extract data with error handling\n",
    "                try:\n",
    "                    laps_df = session.laps.copy() if hasattr(session, 'laps') and session.laps is not None else None\n",
    "                except:\n",
    "                    laps_df = None\n",
    "                try:\n",
    "                    weather_df = pd.DataFrame(session.weather_data) if hasattr(session, 'weather_data') and session.weather_data is not None else None\n",
    "                except:\n",
    "                    weather_df = None\n",
    "                try:\n",
    "                    messages_df = pd.DataFrame(session.race_control_messages) if hasattr(session, 'race_control_messages') and session.race_control_messages is not None else None\n",
    "                except:\n",
    "                    messages_df = None\n",
    "                \n",
    "                success = True\n",
    "                print(f\"  Loaded {s}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count < max_retries:\n",
    "                    sleep_time = 2 ** retry_count\n",
    "                    print(f'  Retry {retry_count}/{max_retries} for {year} {gp} {s}: {e}. Sleeping for {sleep_time}s...')\n",
    "                    time.sleep(sleep_time)\n",
    "                else:\n",
    "                    print(f'  Failed after {max_retries} retries for {year} {gp} {s}: {e}')\n",
    "            \n",
    "            finally:\n",
    "                # Delete session object immediately to release resources\n",
    "                if session is not None:\n",
    "                    del session\n",
    "                gc.collect()\n",
    "        \n",
    "        if not success:\n",
    "            continue\n",
    "        \n",
    "        # Get race ID\n",
    "        race_key = f'{gp}_{year}'\n",
    "        race_id_value = race_id_map.get(race_key)\n",
    "        if race_id_value is None:\n",
    "            print(f'  Warning: No race_id found for: {race_key}')\n",
    "        \n",
    "        # Add race_id and session columns to each DataFrame and merge\n",
    "        if laps_df is not None and not laps_df.empty:\n",
    "            laps_df['race_id'] = race_id_value\n",
    "            laps_df['session'] = s\n",
    "            all_laps = pd.concat([all_laps, laps_df], ignore_index=True)\n",
    "        if weather_df is not None and not weather_df.empty:\n",
    "            weather_df['race_id'] = race_id_value\n",
    "            weather_df['session'] = s\n",
    "            all_weather = pd.concat([all_weather, weather_df], ignore_index=True)\n",
    "        if messages_df is not None and not messages_df.empty:\n",
    "            messages_df['race_id'] = race_id_value\n",
    "            messages_df['session'] = s\n",
    "            all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n",
    "\n",
    "        # Clean up DataFrames after each session\n",
    "        del laps_df, weather_df, messages_df\n",
    "        \n",
    "        # Add delay between sessions to avoid rate limiting\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Force garbage collection after each race\n",
    "    gc.collect()\n",
    "    \n",
    "    # Longer delay between races\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Save intermediate results every 5 races\n",
    "    if (url_idx + 1) % 5 == 0:\n",
    "        print(f\"Saving intermediate results after race {url_idx + 1}...\")\n",
    "        all_laps.to_csv('../data/raw/lap_data_raw_temp.csv', index=False)\n",
    "        all_weather.to_csv('../data/raw/weather_data_raw_temp.csv', index=False)\n",
    "        all_messages.to_csv('../data/raw/messages_data_raw_temp.csv', index=False)\n",
    "        print(f\"  Saved: {len(all_laps)} laps, {len(all_weather)} weather records, {len(all_messages)} messages\")\n",
    "    \n",
    "# Save final DataFrames to CSVs\n",
    "all_laps.to_csv('../data/raw/lap_data_raw.csv', index=False)\n",
    "all_weather.to_csv('../data/raw/weather_data_raw.csv', index=False)\n",
    "all_messages.to_csv('../data/raw/messages_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c689f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (2.42 GB) C:\\Users\\jackw\\AppData\\Local\\Temp\\fastf1\n",
      "core           INFO \tLoading data for Styrian Grand Prix - Practice 1 [v3.6.1]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "_api           INFO \tFetching session status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "_api           INFO \tFetching track status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
      "_api           INFO \tFetching timing data...\n",
      "_api           INFO \tParsing timing data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "_api           INFO \tFetching timing app data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "req            INFO \tNo cached data found for car_data. Loading data...\n",
      "_api           INFO \tFetching car data...\n",
      "_api           INFO \tParsing car data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for position_data. Loading data...\n",
      "_api           INFO \tFetching position data...\n",
      "_api           INFO \tParsing position data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for weather_data. Loading data...\n",
      "_api           INFO \tFetching weather data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for race_control_messages. Loading data...\n",
      "_api           INFO \tFetching race control messages...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['3', '4', '5', '6', '7', '8', '10', '11', '16', '18', '20', '23', '26', '31', '33', '40', '44', '55', '77', '88']\n"
     ]
    }
   ],
   "source": [
    "# Enable cache (important for performance)\n",
    "# First ensure the cache directory exists\n",
    "#import os\n",
    "#cache_dir = \"cache\"\n",
    "#if not os.path.exists(cache_dir):\n",
    "    #os.makedirs(cache_dir)\n",
    "    #print(f\"Created cache directory: {cache_dir}\")\n",
    "\n",
    "#fastf1.Cache.enable_cache(cache_dir)  # uses the created \"cache\" folder to store data\n",
    "\n",
    "# Load a session: example Bahrain GP 2023 Qualifying\n",
    "session = fastf1.get_session(2020, 'styria', 'fp1')\n",
    "session.load(weather=True)  # only load weather data as requested\n",
    "\n",
    "# Weather data is stored in session.weather_data (a structured numpy array)\n",
    "weather_array = session.weather_data\n",
    "\n",
    "# Convert weather data to DataFrame\n",
    "weather_df = pd.DataFrame(weather_array)\n",
    "\n",
    "# Display weather data\n",
    "weather_df\n",
    "\n",
    "# Save weather dataframe to CSV file\n",
    "weather_df.to_csv(\"example_weather.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0995c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirTemp_mean        15.707865\n",
      "AirTemp_min              15.1\n",
      "AirTemp_max              16.6\n",
      "AirTemp_std           0.37574\n",
      "TrackTemp_mean      18.942135\n",
      "TrackTemp_min            18.3\n",
      "TrackTemp_max            19.4\n",
      "TrackTemp_std        0.276315\n",
      "WindSpeed_mean       3.475281\n",
      "WindSpeed_min             0.7\n",
      "WindSpeed_max             6.9\n",
      "WindSpeed_std        1.242267\n",
      "Humidity_mean       78.421348\n",
      "Humidity_min             68.0\n",
      "Humidity_max             92.0\n",
      "Humidity_std          6.50658\n",
      "Pressure_mean     1009.901685\n",
      "Pressure_min           1009.0\n",
      "Pressure_max           1010.7\n",
      "Pressure_std         0.444994\n",
      "Rainfall_any             True\n",
      "Rainfall_mean        0.325843\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example with weather data\n",
    "numeric_columns = ['AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity', 'Pressure']\n",
    "boolean_columns = ['Rainfall']\n",
    "\n",
    "session_weather_features = aggregate_columns(\n",
    "    weather_df, \n",
    "    columns=numeric_columns, \n",
    "    boolean_columns=boolean_columns\n",
    ")\n",
    "\n",
    "print(session_weather_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
