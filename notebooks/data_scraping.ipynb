{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8b3a9f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Jack Wilson\n",
    "9/23/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7868b9",
   "metadata": {},
   "source": [
    "This notebook outlines scraping and collecting of all data raw data used in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e71531",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, random, re, os, gc, shutil, pickle, tempfile\n",
    "from math import e\n",
    "\n",
    "import fastf1\n",
    "import logging\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "from src.data_functions import load_id_map, save_id_map, init_col_map, scrape_url_table, constructor_mapping\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7736f",
   "metadata": {},
   "source": [
    "# DataFrame Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fc566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968658e",
   "metadata": {},
   "source": [
    "# F1 Site 2001-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6714b5",
   "metadata": {},
   "source": [
    "## Race Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ee0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish web browser and initial variables\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "year_begin = 2001\n",
    "year_end = 2017\n",
    "race_urls = []\n",
    "\n",
    "while year_begin <= year_end:\n",
    "\n",
    "    # Use the years to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "    \n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "    \n",
    "    year_begin += 1\n",
    "\n",
    "browser.close()\n",
    "\n",
    "# Save links to file\n",
    "load_id_map('../data/raw/links_2001_2017.pkl')\n",
    "save_id_map('../data/raw/links_2001_2017.pkl', race_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83756d04",
   "metadata": {},
   "source": [
    "## Race Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581437d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables\n",
    "urls = load_id_map('../data/raw/links_2001_2017.pkl')\n",
    "total_cols = 7\n",
    "col_idx_map = {\n",
    "    'driver_id': 2,\n",
    "    'position': 0,\n",
    "    'driver_name': 2,\n",
    "    'points': 6}\n",
    "id_cols = ['driver_id']\n",
    "\n",
    "# Scrape 2001-2017 results\n",
    "df = scrape_url_table(\n",
    "    urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols)\n",
    "df.to_csv('../data/raw/race_results_raw_2001-2017.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164dcb2",
   "metadata": {},
   "source": [
    "# F1 Site 2018+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23231d0",
   "metadata": {},
   "source": [
    "## Race Links & Circuit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2be5511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish web browser and initial variables\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "year_begin = 2018\n",
    "year_end = datetime.now().year\n",
    "race_urls = []\n",
    "round_number = []\n",
    "\n",
    "while year_begin <= year_end:\n",
    "    r = 1  \n",
    "\n",
    "    # Use the years to crawl across season pages\n",
    "    url = \"https://www.formula1.com/en/results/\" + str(year_begin) + \"/races\"\n",
    "    browser.get(url)\n",
    "    \n",
    "    table = browser.find_elements(By.TAG_NAME, \"table\")\n",
    "    for tr in table:\n",
    "        rows = tr.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Url for each specific race\n",
    "            link = cells[0].find_element(By.TAG_NAME, \"a\")\n",
    "            race_urls.append(link.get_attribute(\"href\"))\n",
    "            round_number.append(r)\n",
    "            r += 1 \n",
    "\n",
    "    year_begin += 1\n",
    "\n",
    "browser.close()\n",
    "\n",
    "link_data = pd.DataFrame({'race_url': race_urls, 'round_number': round_number})\n",
    "link_data.to_csv('../data/raw/rounds_raw.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# Save links to file\n",
    "load_id_map('../data/raw/links_2018+.pkl')\n",
    "save_id_map('../data/raw/links_2018+.pkl', race_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9903d16",
   "metadata": {},
   "source": [
    "## Race Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "total_cols = 7\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'circuit_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text,\n",
    "    'team_id': 3,\n",
    "    'year': lambda browser: int(browser.current_url.split(\"/\")[5]),\n",
    "    'race_url': lambda browser: browser.current_url,\n",
    "    'circuit_name': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text,\n",
    "    'driver_name': 2,\n",
    "    'team_name': 3,\n",
    "    'end_position': 0,\n",
    "    'points': 6,\n",
    "    'laps_completed': 4}\n",
    "id_cols = ['race_id', 'driver_id', 'circuit_id', 'team_id']\n",
    "page_lvl_cols = ['race_id', 'circuit_id', 'year', 'race_url', 'circuit_name']\n",
    "\n",
    "# Scrape 2018+ results\n",
    "df = scrape_url_table(\n",
    "    urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/race_results_raw_2018+.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754febc2",
   "metadata": {},
   "source": [
    "## Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create practice URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "practice_urls = []\n",
    "for url in urls:\n",
    "    for practice_num in [1, 2, 3]:\n",
    "        practice_url = url.replace('/race-result', f'/practice/{practice_num}')\n",
    "        practice_urls.append(practice_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 6\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'session_type': lambda browser: browser.current_url.split(\"/\")[9] + browser.current_url.split(\"/\")[10],\n",
    "    'lap_time': 4,\n",
    "    'lap_count': 5,\n",
    "    'position': 0}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id', 'session_type']\n",
    "\n",
    "# Scrape practice results\n",
    "df = scrape_url_table(\n",
    "    practice_urls,\n",
    "    total_cols, col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/pratice_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bef32a",
   "metadata": {},
   "source": [
    "## Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create qualifying URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "qualifying_urls = []\n",
    "for url in urls:\n",
    "    qual_url = url.replace('/race-result', '/qualifying')\n",
    "    qualifying_urls.append(qual_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'q1_time': 4,\n",
    "    'q2_time': 5,\n",
    "    'q3_time': 6,\n",
    "    'qual_position': 0,\n",
    "    'qual_laps': 7}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape qualifying results\n",
    "df = scrape_url_table(\n",
    "    qualifying_urls,\n",
    "    total_cols, col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/qualifying_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c87aa8",
   "metadata": {},
   "source": [
    "## Starting Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e59620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create starting grid URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "starting_urls = []\n",
    "for url in urls:\n",
    "    start_url = url.replace('/race-result', '/starting-grid')\n",
    "    starting_urls.append(start_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 5\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'start_position': 0}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape starting grid results\n",
    "df = scrape_url_table(\n",
    "    starting_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/starting_grid_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ec1b3",
   "metadata": {},
   "source": [
    "## Pit Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b56251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pit stop URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "pit_urls = []\n",
    "for url in urls:\n",
    "    ps_url = url.replace('/race-result', '/pit-stop-summary')\n",
    "    pit_urls.append(ps_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'stop_number': 0,\n",
    "    'stop_lap': 4,\n",
    "    'pits_time': 6}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape pit stop results\n",
    "df = scrape_url_table(\n",
    "    pit_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/pit_stop_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d51364",
   "metadata": {},
   "source": [
    "## Fastest Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission denied on attempt 1, retrying in 1 second...\n"
     ]
    }
   ],
   "source": [
    "# Create fastest lap URLs\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "fastest_lap_urls = []\n",
    "for url in urls:\n",
    "    fastest_url = url.replace('/race-result', '/fastest-laps')\n",
    "    fastest_lap_urls.append(fastest_url)\n",
    "\n",
    "# Establish other variables\n",
    "total_cols = 8\n",
    "col_idx_map = {\n",
    "    'race_id': lambda browser: browser.find_element(By.ID, \"content-dropdown\").text + '_' + browser.current_url.split(\"/\")[5],\n",
    "    'driver_id': 2,\n",
    "    'team_id': 3,\n",
    "    'fastest_lap_time': 6,\n",
    "    'lap_number': 4}\n",
    "id_cols = ['race_id', 'driver_id', 'team_id']\n",
    "page_lvl_cols = ['race_id']\n",
    "\n",
    "# Scrape fastest lap results\n",
    "df = scrape_url_table(\n",
    "    fastest_lap_urls,\n",
    "    total_cols,\n",
    "    col_idx_map,\n",
    "    id_cols,\n",
    "    page_lvl_cols=page_lvl_cols,\n",
    "    id_mask=constructor_mapping)\n",
    "df.to_csv('../data/raw/fastest_lap_results_raw.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924b539",
   "metadata": {},
   "source": [
    "# FastF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00569f46",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c523242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing race 1/167: 2018 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 2/167: 2018 Bahrain\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retry_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     42\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtelemetry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Extract data with error handling\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\core.py:1439\u001b[0m, in \u001b[0;36mSession.load\u001b[1;34m(self, laps, telemetry, weather, messages, livedata)\u001b[0m\n\u001b[0;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_total_lap_count(livedata\u001b[38;5;241m=\u001b[39mlivedata)\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_track_status_data(livedata\u001b[38;5;241m=\u001b[39mlivedata)\n\u001b[1;32m-> 1439\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_laps_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlivedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlivedata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_first_lap_time_from_ergast()\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m telemetry:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\logger.py:151\u001b[0m, in \u001b[0;36msoft_exceptions.<locals>.__decorator.<locals>.__wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LoggingManager\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    153\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\core.py:1662\u001b[0m, in \u001b[0;36mSession._load_laps_data\u001b[1;34m(self, livedata)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_track_status_to_laps(laps)\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_laps \u001b[38;5;241m=\u001b[39m Laps(laps, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _force_default_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1662\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_lap_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\logger.py:151\u001b[0m, in \u001b[0;36msoft_exceptions.<locals>.__decorator.<locals>.__wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LoggingManager\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    153\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\core.py:2228\u001b[0m, in \u001b[0;36mSession._check_lap_accuracy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2226\u001b[0m prev_lap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m integrity_errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 2228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, lap \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDriverNumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdrv\u001b[49m\u001b[43m]\u001b[49m \\\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m   2230\u001b[0m     lap_integrity_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# require existence, non-existence and specific values for\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# some variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4155\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:110\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;66;03m# i.e. DatetimeArray, TimedeltaArray\u001b[39;00m\n\u001b[0;32m    109\u001b[0m         arr \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDArrayBackedExtensionArray\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr)\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:168\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.take\u001b[1;34m(self, indices, allow_fill, fill_value, axis)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_fill:\n\u001b[0;32m    166\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_scalar(fill_value)\n\u001b[1;32m--> 168\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_backing_data(new_data)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1234\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_fill:\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# Pandas style, -1 means NA\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     validate_indices(indices, arr\u001b[38;5;241m.\u001b[39mshape[axis])\n\u001b[1;32m-> 1234\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m     result \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:369\u001b[0m, in \u001b[0;36m_view_wrapper.<locals>.wrapper\u001b[1;34m(arr, indexer, out, fill_value)\u001b[0m\n\u001b[0;32m    366\u001b[0m         fill_value \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM8[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    367\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m fill_wrap(fill_value)\n\u001b[1;32m--> 369\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize urls and sessions\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "sessions_collected = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "fastf1.Cache.disabled = True\n",
    "\n",
    "# Suppress FastF1 logging output\n",
    "fastf1_logger = logging.getLogger('fastf1')\n",
    "fastf1_logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "# Initialize empty DataFrames to collect all data\n",
    "all_laps = pd.DataFrame()\n",
    "all_weather = pd.DataFrame()\n",
    "all_messages = pd.DataFrame()\n",
    "\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for url_idx, url in enumerate(urls):\n",
    "    \n",
    "    # Sort year and grand prix from the url\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = url.split('/')[8].replace('-', ' ').title().replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    \n",
    "    print(f\"\\nProcessing race {url_idx + 1}/{len(urls)}: {year} {gp}\")\n",
    "    \n",
    "    for s in sessions_collected:\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        success = False\n",
    "        \n",
    "        laps_df = None\n",
    "        weather_df = None\n",
    "        messages_df = None\n",
    "        session = None\n",
    "\n",
    "        # Load session with retry\n",
    "        while retry_count < max_retries and not success:\n",
    "            try:\n",
    "                gc.collect()\n",
    "                \n",
    "                session = fastf1.get_session(year, gp, s)\n",
    "                if retry_count > 0:\n",
    "                    time.sleep(3)\n",
    "                session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "                \n",
    "                # Extract data with error handling\n",
    "                try:\n",
    "                    laps_df = session.laps.copy() if hasattr(session, 'laps') and session.laps is not None else None\n",
    "                except:\n",
    "                    laps_df = None\n",
    "                try:\n",
    "                    weather_df = pd.DataFrame(session.weather_data) if hasattr(session, 'weather_data') and session.weather_data is not None else None\n",
    "                except:\n",
    "                    weather_df = None\n",
    "                try:\n",
    "                    messages_df = pd.DataFrame(session.race_control_messages) if hasattr(session, 'race_control_messages') and session.race_control_messages is not None else None\n",
    "                except:\n",
    "                    messages_df = None\n",
    "                \n",
    "                success = True\n",
    "                print(f\"  Loaded {s}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count < max_retries:\n",
    "                    sleep_time = 2 ** retry_count\n",
    "                    print(f'  Retry {retry_count}/{max_retries} for {year} {gp} {s}: {e}. Sleeping for {sleep_time}s...')\n",
    "                    time.sleep(sleep_time)\n",
    "                else:\n",
    "                    print(f'  Failed after {max_retries} retries for {year} {gp} {s}: {e}')\n",
    "            \n",
    "            finally:\n",
    "                # Delete session object immediately to release resources\n",
    "                if session is not None:\n",
    "                    del session\n",
    "                gc.collect()\n",
    "        \n",
    "        if not success:\n",
    "            continue\n",
    "        \n",
    "        # Get race ID\n",
    "        race_key = f'{gp}_{year}'\n",
    "        race_id_value = race_id_map.get(race_key)\n",
    "        if race_id_value is None:\n",
    "            print(f'  Warning: No race_id found for: {race_key}')\n",
    "        \n",
    "        # Add race_id and session columns to each DataFrame and merge\n",
    "        if laps_df is not None and not laps_df.empty:\n",
    "            laps_df['race_id'] = race_id_value\n",
    "            laps_df['session'] = s\n",
    "            all_laps = pd.concat([all_laps, laps_df], ignore_index=True)\n",
    "        if weather_df is not None and not weather_df.empty:\n",
    "            weather_df['race_id'] = race_id_value\n",
    "            weather_df['session'] = s\n",
    "            all_weather = pd.concat([all_weather, weather_df], ignore_index=True)\n",
    "        if messages_df is not None and not messages_df.empty:\n",
    "            messages_df['race_id'] = race_id_value\n",
    "            messages_df['session'] = s\n",
    "            all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n",
    "\n",
    "        # Clean up DataFrames after each session\n",
    "        del laps_df, weather_df, messages_df\n",
    "    \n",
    "    # Force garbage collection after each race\n",
    "    gc.collect()\n",
    "    \n",
    "    # Save intermediate results every 5 races\n",
    "    if (url_idx + 1) % 5 == 0:\n",
    "        print(f\"Saving intermediate results after race {url_idx + 1}...\")\n",
    "        all_laps.to_csv('../data/raw/lap_data_raw_temp.csv', index=False)\n",
    "        all_weather.to_csv('../data/raw/weather_data_raw_temp.csv', index=False)\n",
    "        all_messages.to_csv('../data/raw/messages_data_raw_temp.csv', index=False)\n",
    "        print(f\"  Saved: {len(all_laps)} laps, {len(all_weather)} weather records, {len(all_messages)} messages\")\n",
    "    \n",
    "# Save final DataFrames to CSVs\n",
    "all_laps.to_csv('../data/raw/lap_data_raw.csv', index=False)\n",
    "all_weather.to_csv('../data/raw/weather_data_raw.csv', index=False)\n",
    "all_messages.to_csv('../data/raw/messages_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3c5d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1/167 | 2018 Australia ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 82\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Launch a new Python process for this race\u001b[39;00m\n\u001b[0;32m     81\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m---> 82\u001b[0m     [sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;18;43m__file__\u001b[39;49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--race\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(year), gp, \u001b[38;5;28mstr\u001b[39m(race_id_value), CACHE_DIR, OUTPUT_DIR],\n\u001b[0;32m     83\u001b[0m     check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Pause briefly between races\u001b[39;00m\n\u001b[0;32m     87\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "# If we're inside a subprocess, these will be passed in as args\n",
    "if len(sys.argv) > 1 and sys.argv[1] == \"--race\":\n",
    "    # Subprocess mode: handle a single race\n",
    "    year = int(sys.argv[2])\n",
    "    gp = sys.argv[3]\n",
    "    race_id_value = sys.argv[4]\n",
    "    cache_dir = sys.argv[5]\n",
    "    output_dir = sys.argv[6]\n",
    "\n",
    "    sessions = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "    fastf1.Cache.enable_cache(cache_dir)\n",
    "\n",
    "    for s in sessions:\n",
    "        try:\n",
    "            gc.collect()\n",
    "            session = fastf1.get_session(year, gp, s)\n",
    "            session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "            print(f\" Loaded {year} {gp} {s}\")\n",
    "\n",
    "            # Extract safely\n",
    "            laps = getattr(session, 'laps', pd.DataFrame())\n",
    "            weather = getattr(session, 'weather_data', pd.DataFrame())\n",
    "            messages = getattr(session, 'race_control_messages', pd.DataFrame())\n",
    "\n",
    "            for df in [laps, weather, messages]:\n",
    "                if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                    df[\"race_id\"] = race_id_value\n",
    "                    df[\"session\"] = s\n",
    "\n",
    "            # Save\n",
    "            prefix = f\"{output_dir}/{year}_{gp}_{s}\"\n",
    "            if not laps.empty:\n",
    "                laps.to_parquet(f\"{prefix}_laps.parquet\")\n",
    "            if not weather.empty:\n",
    "                weather.to_parquet(f\"{prefix}_weather.parquet\")\n",
    "            if not messages.empty:\n",
    "                messages.to_parquet(f\"{prefix}_messages.parquet\")\n",
    "\n",
    "            print(f\" Saved {year} {gp} {s}\")\n",
    "            del session\n",
    "            gc.collect()\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error for {year} {gp} {s}: {e}\")\n",
    "            time.sleep(3)\n",
    "    sys.exit(0)\n",
    "\n",
    "# === Main controller ===\n",
    "CACHE_DIR = \"../data/cache\"\n",
    "OUTPUT_DIR = \"../data/raw/fastf1\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = (\n",
    "        url.split('/')[8]\n",
    "        .replace('-', ' ')\n",
    "        .title()\n",
    "        .replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    )\n",
    "    race_key = f\"{gp}_{year}\"\n",
    "    race_id_value = race_id_map.get(race_key, \"unknown\")\n",
    "\n",
    "    print(f\"\\n=== {idx+1}/{len(urls)} | {year} {gp} ===\")\n",
    "\n",
    "    # Launch a new Python process for this race\n",
    "    subprocess.run(\n",
    "        [sys.executable, __file__, \"--race\", str(year), gp, str(race_id_value), CACHE_DIR, OUTPUT_DIR],\n",
    "        check=False,\n",
    "    )\n",
    "\n",
    "    # Pause briefly between races\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53932cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing race 1/167: 2018 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 2/167: 2018 Bahrain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 3/167: 2018 China\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 4/167: 2018 Azerbaijan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 5/167: 2018 Spain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 5...\n",
      "  Saved: 13193 laps, 2186 weather records, 1001 messages\n",
      "\n",
      "Processing race 6/167: 2018 Monaco\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 7/167: 2018 Canada\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 8/167: 2018 France\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 9/167: 2018 Austria\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 10/167: 2018 Great Britain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 10...\n",
      "  Saved: 28484 laps, 4367 weather records, 1925 messages\n",
      "\n",
      "Processing race 11/167: 2018 Germany\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 12/167: 2018 Hungary\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 13/167: 2018 Belgium\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 14/167: 2018 Italy\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 15/167: 2018 Singapore\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 15...\n",
      "  Saved: 42036 laps, 6709 weather records, 2666 messages\n",
      "\n",
      "Processing race 16/167: 2018 Russia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 17/167: 2018 Japan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 18/167: 2018 United States\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 19/167: 2018 Mexico\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 20/167: 2018 Brazil\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 20...\n",
      "  Saved: 55359 laps, 9187 weather records, 3459 messages\n",
      "\n",
      "Processing race 21/167: 2018 Abu Dhabi\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 22/167: 2019 Australia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 23/167: 2019 Bahrain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 24/167: 2019 China\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 25/167: 2019 Azerbaijan\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 25...\n",
      "  Saved: 68148 laps, 11698 weather records, 4273 messages\n",
      "\n",
      "Processing race 26/167: 2019 Spain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 27/167: 2019 Monaco\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 28/167: 2019 Canada\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 29/167: 2019 France\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 30/167: 2019 Austria\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intermediate results after race 30...\n",
      "  Saved: 84657 laps, 14213 weather records, 5178 messages\n",
      "\n",
      "Processing race 31/167: 2019 Great Britain\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Race\n",
      "\n",
      "Processing race 32/167: 2019 Germany\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 33/167: 2019 Hungary\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 34/167: 2019 Belgium\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 35/167: 2019 Italy\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 35...\n",
      "  Saved: 97870 laps, 16744 weather records, 6032 messages\n",
      "\n",
      "Processing race 36/167: 2019 Singapore\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 37/167: 2019 Russia\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 38/167: 2019 Japan\n",
      "  Loaded FP1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 39/167: 2019 Mexico\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_12320\\4116120806.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 40/167: 2019 United States\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "Saving intermediate results after race 40...\n",
      "  Saved: 110061 laps, 19022 weather records, 6843 messages\n",
      "\n",
      "Processing race 41/167: 2019 Brazil\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 42/167: 2019 Abu Dhabi\n",
      "  Loaded FP1\n",
      "  Loaded FP2\n",
      "  Loaded FP3\n",
      "  Loaded Qualifying\n",
      "  Loaded Race\n",
      "\n",
      "Processing race 43/167: 2020 Austria\n",
      "  Retry 1/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP1: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP1: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP2: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP2: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria FP3: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria FP3: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria Qualifying: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria Qualifying: Failed to load any schedule data.\n",
      "  Retry 1/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 8s...\n",
      "  Retry 4/5 for 2020 Austria Race: Failed to load any schedule data.. Sleeping for 16s...\n",
      "  Failed after 5 retries for 2020 Austria Race: Failed to load any schedule data.\n",
      "\n",
      "Processing race 44/167: 2020 Styria\n",
      "  Retry 1/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 2s...\n",
      "  Retry 2/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 4s...\n",
      "  Retry 3/5 for 2020 Styria FP1: Failed to load any schedule data.. Sleeping for 8s...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m---> 46\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mfastf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     session\u001b[38;5;241m.\u001b[39mload(laps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, telemetry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, weather\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Extract data with error handling\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:310\u001b[0m, in \u001b[0;36mget_session\u001b[1;34m(year, gp, identifier, backend, force_ergast)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_session\u001b[39m(\n\u001b[0;32m    243\u001b[0m         year: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    244\u001b[0m         gp: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m         force_ergast: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    249\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Session:\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a :class:`~fastf1.core.Session` object based on year, event name\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    and session identifier.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m            from the ergast database to create the event schedule\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[43mget_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ergast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ergast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m event\u001b[38;5;241m.\u001b[39mget_session(identifier)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:405\u001b[0m, in \u001b[0;36mget_event\u001b[1;34m(year, gp, backend, force_ergast, strict_search, exact_match)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_event\u001b[39m(\n\u001b[0;32m    351\u001b[0m         year: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    352\u001b[0m         gp: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m         exact_match: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an :class:`~fastf1.events.Event` object for a specific\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    season and gp.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.2\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     schedule \u001b[38;5;241m=\u001b[39m \u001b[43mget_event_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mforce_ergast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ergast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    410\u001b[0m         event \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39mget_event_by_name(\n\u001b[0;32m    411\u001b[0m             gp, strict_search\u001b[38;5;241m=\u001b[39mstrict_search, exact_match\u001b[38;5;241m=\u001b[39mexact_match)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:517\u001b[0m, in \u001b[0;36mget_event_schedule\u001b[1;34m(year, include_testing, backend, force_ergast)\u001b[0m\n\u001b[0;32m    515\u001b[0m schedule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m--> 517\u001b[0m     schedule \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schedule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\logger.py:151\u001b[0m, in \u001b[0;36msoft_exceptions.<locals>.__decorator.<locals>.__wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LoggingManager\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    153\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\events.py:659\u001b[0m, in \u001b[0;36m_get_schedule_from_f1_timing\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;129m@soft_exceptions\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 API schedule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    655\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load schedule from F1 API backend!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    656\u001b[0m                  _logger)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_schedule_from_f1_timing\u001b[39m(year: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# create an event schedule using data from the F1 API\u001b[39;00m\n\u001b[1;32m--> 659\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfastf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseason_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/static/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     data \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:479\u001b[0m, in \u001b[0;36mCache.api_request_wrapper.<locals>._cached_api_request\u001b[1;34m(api_path, **func_kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# cached data does not yet exist for this api request\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo cached data found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    478\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 479\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_write_cache(data, cache_file_path)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\_api.py:1678\u001b[0m, in \u001b[0;36mseason_schedule\u001b[1;34m(path, response)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1677\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching season schedule...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1678\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# no response received\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SessionNotAvailableError(\n\u001b[0;32m   1681\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data for this session! If this session only finished \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1682\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecently, please try again in a few minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1683\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\_api.py:1752\u001b[0m, in \u001b[0;36mfetch_page\u001b[1;34m(path, name)\u001b[0m\n\u001b[0;32m   1749\u001b[0m is_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjsonStream\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m page\n\u001b[0;32m   1750\u001b[0m is_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.z.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m page\n\u001b[1;32m-> 1752\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mCache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m   1755\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to livetiming mirror (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url_mirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:303\u001b[0m, in \u001b[0;36mCache.requests_get\u001b[1;34m(cls, url, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_request_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:347\u001b[0m, in \u001b[0;36mCache._cached_request\u001b[1;34m(cls, method, url, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# catch TypeError raised by outdated requests-cache version if the\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# cache was created with a newer version\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# github.com/requests-cache/requests-cache/issues/973\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using an outdated version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequests-cache. Consider upgrading.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:127\u001b[0m, in \u001b[0;36mCacheMixin.get\u001b[1;34m(self, url, params, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyResponse:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:183\u001b[0m, in \u001b[0;36mCacheMixin.request\u001b[1;34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m headers \u001b[38;5;241m=\u001b[39m set_request_headers(headers, expire_after, only_if_cached, refresh, force_refresh)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch_form_boundary() \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:230\u001b[0m, in \u001b[0;36mCacheMixin.send\u001b[1;34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resend(request, actions, cached_response, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m actions\u001b[38;5;241m.\u001b[39msend_request:\n\u001b[1;32m--> 230\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     response \u001b[38;5;241m=\u001b[39m cached_response  \u001b[38;5;66;03m# type: ignore  # Guaranteed to be non-None by this point\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests_cache\\session.py:254\u001b[0m, in \u001b[0;36mCacheMixin._send_and_cache\u001b[1;34m(self, request, actions, cached_response, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a request and cache the response, unless disabled by settings or headers.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03mIf applicable, also handle conditional requests.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    253\u001b[0m request \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mupdate_request(request)\n\u001b[1;32m--> 254\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m actions\u001b[38;5;241m.\u001b[39mupdate_from_response(response)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions\u001b[38;5;241m.\u001b[39mskip_write:\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:134\u001b[0m, in \u001b[0;36m_SessionWithRateLimiting.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pattern\u001b[38;5;241m.\u001b[39mmatch(request\u001b[38;5;241m.\u001b[39murl):\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lim \u001b[38;5;129;01min\u001b[39;00m limiters:\n\u001b[0;32m    133\u001b[0m             \u001b[38;5;66;03m# apply all defined limiters\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m             \u001b[43mlim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fastf1\\req.py:83\u001b[0m, in \u001b[0;36m_MinIntervalLimitDelay.limit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m t_now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (delta \u001b[38;5;241m:=\u001b[39m (t_now \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t_last)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interval:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     t_now \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interval \u001b[38;5;241m-\u001b[39m delta\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t_last \u001b[38;5;241m=\u001b[39m t_now\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Initialize urls and sessions\n",
    "urls = load_id_map('../data/raw/links_2018+.pkl')\n",
    "sessions_collected = ['FP1', 'FP2', 'FP3', 'Qualifying', 'Race']\n",
    "fastf1.Cache.disabled = True\n",
    "\n",
    "# Suppress FastF1 logging output\n",
    "fastf1_logger = logging.getLogger('fastf1')\n",
    "fastf1_logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "# Initialize empty DataFrames to collect all data\n",
    "all_laps = pd.DataFrame()\n",
    "all_weather = pd.DataFrame()\n",
    "all_messages = pd.DataFrame()\n",
    "\n",
    "race_id_map = load_id_map('../data/raw/race_id_map.pkl')\n",
    "\n",
    "for url_idx, url in enumerate(urls):\n",
    "    \n",
    "    # Sort year and grand prix from the url\n",
    "    year = int(url.split('/')[5])\n",
    "    gp = url.split('/')[8].replace('-', ' ').title().replace('Emilia Romagna', 'Emilia-Romagna')\n",
    "    \n",
    "    print(f\"\\nProcessing race {url_idx + 1}/{len(urls)}: {year} {gp}\")\n",
    "    \n",
    "    for s in sessions_collected:\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        success = False\n",
    "        \n",
    "        laps_df = None\n",
    "        weather_df = None\n",
    "        messages_df = None\n",
    "        session = None\n",
    "\n",
    "        # Load session with retry\n",
    "        while retry_count < max_retries and not success:\n",
    "            try:\n",
    "                gc.collect()\n",
    "                \n",
    "                session = fastf1.get_session(year, gp, s)\n",
    "                session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "                \n",
    "                # Extract data with error handling\n",
    "                try:\n",
    "                    laps_df = session.laps.copy() if hasattr(session, 'laps') and session.laps is not None else None\n",
    "                except:\n",
    "                    laps_df = None\n",
    "                try:\n",
    "                    weather_df = pd.DataFrame(session.weather_data) if hasattr(session, 'weather_data') and session.weather_data is not None else None\n",
    "                except:\n",
    "                    weather_df = None\n",
    "                try:\n",
    "                    messages_df = pd.DataFrame(session.race_control_messages) if hasattr(session, 'race_control_messages') and session.race_control_messages is not None else None\n",
    "                except:\n",
    "                    messages_df = None\n",
    "                \n",
    "                success = True\n",
    "                print(f\"  Loaded {s}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count < max_retries:\n",
    "                    sleep_time = 2 ** retry_count\n",
    "                    print(f'  Retry {retry_count}/{max_retries} for {year} {gp} {s}: {e}. Sleeping for {sleep_time}s...')\n",
    "                    time.sleep(sleep_time)\n",
    "                else:\n",
    "                    print(f'  Failed after {max_retries} retries for {year} {gp} {s}: {e}')\n",
    "            \n",
    "            finally:\n",
    "                # Delete session object immediately to release resources\n",
    "                if session is not None:\n",
    "                    del session\n",
    "                gc.collect()\n",
    "        \n",
    "        if not success:\n",
    "            continue\n",
    "        \n",
    "        # Get race ID\n",
    "        race_key = f'{gp}_{year}'\n",
    "        race_id_value = race_id_map.get(race_key)\n",
    "        if race_id_value is None:\n",
    "            print(f'  Warning: No race_id found for: {race_key}')\n",
    "        \n",
    "        # Add race_id and session columns to each DataFrame and merge\n",
    "        if laps_df is not None and not laps_df.empty:\n",
    "            laps_df['race_id'] = race_id_value\n",
    "            laps_df['session'] = s\n",
    "            all_laps = pd.concat([all_laps, laps_df], ignore_index=True)\n",
    "        if weather_df is not None and not weather_df.empty:\n",
    "            weather_df['race_id'] = race_id_value\n",
    "            weather_df['session'] = s\n",
    "            all_weather = pd.concat([all_weather, weather_df], ignore_index=True)\n",
    "        if messages_df is not None and not messages_df.empty:\n",
    "            messages_df['race_id'] = race_id_value\n",
    "            messages_df['session'] = s\n",
    "            all_messages = pd.concat([all_messages, messages_df], ignore_index=True)\n",
    "\n",
    "        # Clean up DataFrames after each session\n",
    "        del laps_df, weather_df, messages_df\n",
    "        \n",
    "        # Add delay between sessions to avoid rate limiting\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Force garbage collection after each race\n",
    "    gc.collect()\n",
    "    \n",
    "    # Longer delay between races\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Save intermediate results every 5 races\n",
    "    if (url_idx + 1) % 5 == 0:\n",
    "        print(f\"Saving intermediate results after race {url_idx + 1}...\")\n",
    "        all_laps.to_csv('../data/raw/lap_data_raw_temp.csv', index=False)\n",
    "        all_weather.to_csv('../data/raw/weather_data_raw_temp.csv', index=False)\n",
    "        all_messages.to_csv('../data/raw/messages_data_raw_temp.csv', index=False)\n",
    "        print(f\"  Saved: {len(all_laps)} laps, {len(all_weather)} weather records, {len(all_messages)} messages\")\n",
    "    \n",
    "# Save final DataFrames to CSVs\n",
    "all_laps.to_csv('../data/raw/lap_data_raw.csv', index=False)\n",
    "all_weather.to_csv('../data/raw/weather_data_raw.csv', index=False)\n",
    "all_messages.to_csv('../data/raw/messages_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c689f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (2.42 GB) C:\\Users\\jackw\\AppData\\Local\\Temp\\fastf1\n",
      "core           INFO \tLoading data for Styrian Grand Prix - Practice 1 [v3.6.1]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "_api           INFO \tFetching session status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "_api           INFO \tFetching track status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
      "_api           INFO \tFetching timing data...\n",
      "_api           INFO \tParsing timing data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "_api           INFO \tFetching timing app data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "req            INFO \tNo cached data found for car_data. Loading data...\n",
      "_api           INFO \tFetching car data...\n",
      "_api           INFO \tParsing car data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for position_data. Loading data...\n",
      "_api           INFO \tFetching position data...\n",
      "_api           INFO \tParsing position data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for weather_data. Loading data...\n",
      "_api           INFO \tFetching weather data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for race_control_messages. Loading data...\n",
      "_api           INFO \tFetching race control messages...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['3', '4', '5', '6', '7', '8', '10', '11', '16', '18', '20', '23', '26', '31', '33', '40', '44', '55', '77', '88']\n"
     ]
    }
   ],
   "source": [
    "# Enable cache (important for performance)\n",
    "# First ensure the cache directory exists\n",
    "#import os\n",
    "#cache_dir = \"cache\"\n",
    "#if not os.path.exists(cache_dir):\n",
    "    #os.makedirs(cache_dir)\n",
    "    #print(f\"Created cache directory: {cache_dir}\")\n",
    "\n",
    "#fastf1.Cache.enable_cache(cache_dir)  # uses the created \"cache\" folder to store data\n",
    "\n",
    "# Load a session: example Bahrain GP 2023 Qualifying\n",
    "session = fastf1.get_session(2020, 'styria', 'fp1')\n",
    "session.load(weather=True)  # only load weather data as requested\n",
    "\n",
    "# Weather data is stored in session.weather_data (a structured numpy array)\n",
    "weather_array = session.weather_data\n",
    "\n",
    "# Convert weather data to DataFrame\n",
    "weather_df = pd.DataFrame(weather_array)\n",
    "\n",
    "# Display weather data\n",
    "weather_df\n",
    "\n",
    "# Save weather dataframe to CSV file\n",
    "weather_df.to_csv(\"example_weather.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0995c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirTemp_mean        15.707865\n",
      "AirTemp_min              15.1\n",
      "AirTemp_max              16.6\n",
      "AirTemp_std           0.37574\n",
      "TrackTemp_mean      18.942135\n",
      "TrackTemp_min            18.3\n",
      "TrackTemp_max            19.4\n",
      "TrackTemp_std        0.276315\n",
      "WindSpeed_mean       3.475281\n",
      "WindSpeed_min             0.7\n",
      "WindSpeed_max             6.9\n",
      "WindSpeed_std        1.242267\n",
      "Humidity_mean       78.421348\n",
      "Humidity_min             68.0\n",
      "Humidity_max             92.0\n",
      "Humidity_std          6.50658\n",
      "Pressure_mean     1009.901685\n",
      "Pressure_min           1009.0\n",
      "Pressure_max           1010.7\n",
      "Pressure_std         0.444994\n",
      "Rainfall_any             True\n",
      "Rainfall_mean        0.325843\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example with weather data\n",
    "numeric_columns = ['AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity', 'Pressure']\n",
    "boolean_columns = ['Rainfall']\n",
    "\n",
    "session_weather_features = aggregate_columns(\n",
    "    weather_df, \n",
    "    columns=numeric_columns, \n",
    "    boolean_columns=boolean_columns\n",
    ")\n",
    "\n",
    "print(session_weather_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
